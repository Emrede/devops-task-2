{
  "version": 4,
  "terraform_version": "1.1.4",
  "serial": 26,
  "lineage": "1db20147-8b54-0549-7c6e-1c75333328a3",
  "outputs": {},
  "resources": [
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "jenkins",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "jenkins",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "my-jenkins-release",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "2.387.1",
                "chart": "jenkins",
                "name": "my-jenkins-release",
                "namespace": "default",
                "revision": 1,
                "values": "{\"additionalAgents\":{},\"agent\":{\"TTYEnabled\":false,\"additionalContainers\":[],\"alwaysPullImage\":false,\"annotations\":{},\"args\":\"${computer.jnlpmac} ${computer.name}\",\"command\":null,\"componentName\":\"jenkins-agent\",\"connectTimeout\":100,\"containerCap\":10,\"customJenkinsLabels\":[],\"defaultsProviderTemplate\":\"\",\"disableDefaultAgent\":false,\"enabled\":true,\"envVars\":[],\"hostNetworking\":false,\"idleMinutes\":0,\"image\":\"jenkins/inbound-agent\",\"imagePullSecretName\":null,\"jenkinsTunnel\":null,\"jenkinsUrl\":null,\"kubernetesConnectTimeout\":5,\"kubernetesReadTimeout\":15,\"maxRequestsPerHostStr\":\"32\",\"namespace\":null,\"nodeSelector\":{},\"nodeUsageMode\":\"NORMAL\",\"podName\":\"default\",\"podRetention\":\"Never\",\"podTemplates\":{},\"privileged\":false,\"resources\":{\"limits\":{\"cpu\":\"512m\",\"memory\":\"512Mi\"},\"requests\":{\"cpu\":\"512m\",\"memory\":\"512Mi\"}},\"runAsGroup\":null,\"runAsUser\":null,\"secretEnvVars\":[],\"showRawYaml\":true,\"sideContainerName\":\"jnlp\",\"tag\":\"4.11.2-4\",\"volumes\":[],\"websocket\":false,\"workingDir\":\"/home/jenkins/agent\",\"workspaceVolume\":{},\"yamlMergeStrategy\":\"override\",\"yamlTemplate\":\"\"},\"awsSecurityGroupPolicies\":{\"enabled\":false,\"policies\":[{\"name\":\"\",\"podSelector\":{},\"securityGroupIds\":[]}]},\"backup\":{\"activeDeadlineSeconds\":\"\",\"componentName\":\"backup\",\"destination\":\"s3://jenkins-data/backup\",\"enabled\":false,\"env\":[],\"existingSecret\":{},\"extraArgs\":[],\"fsGroup\":1000,\"image\":{\"repository\":\"maorfr/kube-tasks\",\"tag\":\"0.2.0\"},\"imagePullSecretName\":null,\"labels\":{},\"onlyJobs\":false,\"resources\":{\"limits\":{\"cpu\":1,\"memory\":\"1Gi\"},\"requests\":{\"cpu\":1,\"memory\":\"1Gi\"}},\"runAsUser\":1000,\"schedule\":\"0 2 * * *\",\"securityContextCapabilities\":{},\"serviceAccount\":{\"annotations\":{},\"create\":true,\"name\":null},\"usePodSecurityContext\":true},\"checkDeprecation\":true,\"clusterZone\":\"cluster.local\",\"controller\":{\"JCasC\":{\"authorizationStrategy\":\"loggedInUsersCanDoAnything:\\n  allowAnonymousRead: false\",\"configScripts\":{},\"configUrls\":[],\"defaultConfig\":true,\"security\":{\"apiToken\":{\"creationOfLegacyTokenEnabled\":false,\"tokenGenerationOnCreationEnabled\":false,\"usageStatisticsEnabled\":true}},\"securityRealm\":\"local:\\n  allowsSignup: false\\n  enableCaptcha: false\\n  users:\\n  - id: \\\"${chart-admin-username}\\\"\\n    name: \\\"Jenkins Admin\\\"\\n    password: \\\"${chart-admin-password}\\\"\"},\"additionalExistingSecrets\":[],\"additionalPlugins\":[],\"additionalSecrets\":[],\"admin\":{\"existingSecret\":\"\",\"passwordKey\":\"jenkins-admin-password\",\"userKey\":\"jenkins-admin-user\"},\"adminPassword\":\"admin\",\"adminSecret\":true,\"adminUser\":\"admin\",\"affinity\":{},\"agentListenerEnabled\":true,\"agentListenerExternalTrafficPolicy\":null,\"agentListenerHostPort\":null,\"agentListenerLoadBalancerIP\":null,\"agentListenerLoadBalancerSourceRanges\":[\"0.0.0.0/0\"],\"agentListenerNodePort\":null,\"agentListenerPort\":50000,\"agentListenerServiceAnnotations\":{},\"agentListenerServiceType\":\"ClusterIP\",\"backendconfig\":{\"annotations\":{},\"apiVersion\":\"extensions/v1beta1\",\"enabled\":false,\"labels\":{},\"name\":null,\"spec\":{}},\"cloudName\":\"kubernetes\",\"componentName\":\"jenkins-controller\",\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"readOnlyRootFilesystem\":true,\"runAsGroup\":1000,\"runAsUser\":1000},\"csrf\":{\"defaultCrumbIssuer\":{\"enabled\":true,\"proxyCompatability\":true}},\"customInitContainers\":[],\"customJenkinsLabels\":[],\"disableRememberMe\":false,\"disabledAgentProtocols\":[\"JNLP-connect\",\"JNLP2-connect\"],\"enableRawHtmlMarkupFormatter\":false,\"executorMode\":\"NORMAL\",\"existingSecret\":null,\"extraPorts\":[],\"fsGroup\":1000,\"googlePodMonitor\":{\"enabled\":false,\"scrapeEndpoint\":\"/prometheus\",\"scrapeInterval\":\"60s\"},\"healthProbes\":true,\"hostAliases\":[],\"hostNetworking\":false,\"httpsKeyStore\":{\"enable\":false,\"fileName\":\"keystore.jks\",\"httpPort\":8081,\"jenkinsHttpsJksSecretName\":\"\",\"jenkinsKeyStoreBase64Encoded\":\"/u3+7QAAAAIAAAABAAAAAQANamVua2luc2NpLmNvbQAAAW2r/b1ZAAAFATCCBP0wDgYKKwYBBAEq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\\n\",\"password\":\"password\",\"path\":\"/var/jenkins_keystore\"},\"image\":\"jenkins/jenkins\",\"imagePullPolicy\":\"Always\",\"imagePullSecretName\":null,\"ingress\":{\"annotations\":{},\"apiVersion\":\"extensions/v1beta1\",\"enabled\":false,\"hostName\":null,\"labels\":{},\"paths\":[],\"tls\":null},\"initScripts\":[],\"initializeOnce\":false,\"installLatestPlugins\":true,\"installLatestSpecifiedPlugins\":false,\"installPlugins\":[\"kubernetes:3734.v562b_b_a_627ea_c\",\"workflow-aggregator:590.v6a_d052e5a_a_b_5\",\"git:4.13.0\",\"configuration-as-code:1569.vb_72405b_80249\"],\"jenkinsHome\":\"/var/jenkins_home\",\"jenkinsRef\":\"/usr/share/jenkins/ref\",\"jenkinsWar\":\"/usr/share/jenkins/jenkins.war\",\"lifecycle\":null,\"loadBalancerSourceRanges\":[\"0.0.0.0/0\"],\"markupFormatter\":\"plainText\",\"nodeSelector\":{},\"numExecutors\":0,\"overwritePluginsFromImage\":true,\"podAnnotations\":{},\"podDisruptionBudget\":{\"annotations\":{},\"apiVersion\":\"policy/v1beta1\",\"enabled\":false,\"labels\":{}},\"podLabels\":{},\"priorityClassName\":null,\"probes\":{\"livenessProbe\":{\"failureThreshold\":5,\"httpGet\":{\"path\":\"{{ default \\\"\\\" .Values.controller.jenkinsUriPrefix }}/login\",\"port\":\"http\"},\"periodSeconds\":10,\"timeoutSeconds\":5},\"readinessProbe\":{\"failureThreshold\":3,\"httpGet\":{\"path\":\"{{ default \\\"\\\" .Values.controller.jenkinsUriPrefix }}/login\",\"port\":\"http\"},\"periodSeconds\":10,\"timeoutSeconds\":5},\"startupProbe\":{\"failureThreshold\":12,\"httpGet\":{\"path\":\"{{ default \\\"\\\" .Values.controller.jenkinsUriPrefix }}/login\",\"port\":\"http\"},\"periodSeconds\":10,\"timeoutSeconds\":5}},\"projectNamingStrategy\":\"standard\",\"prometheus\":{\"alertingRulesAdditionalLabels\":{},\"alertingrules\":[],\"enabled\":false,\"metricRelabelings\":[],\"prometheusRuleNamespace\":\"\",\"relabelings\":[],\"scrapeEndpoint\":\"/prometheus\",\"scrapeInterval\":\"60s\",\"serviceMonitorAdditionalLabels\":{}},\"resources\":{\"limits\":{\"cpu\":\"2000m\",\"memory\":\"4096Mi\"},\"requests\":{\"cpu\":\"50m\",\"memory\":\"256Mi\"}},\"route\":{\"annotations\":{},\"enabled\":false,\"labels\":{}},\"runAsUser\":1000,\"schedulerName\":\"\",\"scriptApproval\":[],\"secondaryingress\":{\"annotations\":{},\"apiVersion\":\"extensions/v1beta1\",\"enabled\":false,\"hostName\":null,\"labels\":{},\"paths\":[],\"tls\":null},\"secretClaims\":[],\"securityContextCapabilities\":{},\"serviceAnnotations\":{},\"serviceExternalTrafficPolicy\":null,\"serviceLabels\":{},\"servicePort\":8080,\"serviceType\":\"ClusterIP\",\"sidecars\":{\"configAutoReload\":{\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"readOnlyRootFilesystem\":true},\"enabled\":true,\"folder\":\"/var/jenkins_home/casc_configs\",\"image\":\"kiwigrid/k8s-sidecar:1.15.0\",\"imagePullPolicy\":\"IfNotPresent\",\"reqRetryConnect\":10,\"resources\":{},\"sshTcpPort\":1044},\"other\":[]},\"statefulSetAnnotations\":{},\"statefulSetLabels\":{},\"tagLabel\":\"jdk11\",\"targetPort\":8080,\"terminationGracePeriodSeconds\":null,\"terminationMessagePath\":null,\"terminationMessagePolicy\":null,\"testEnabled\":true,\"tolerations\":[],\"updateStrategy\":{},\"usePodSecurityContext\":true},\"cronJob\":{\"apiVersion\":\"batch/v1\"},\"networkPolicy\":{\"apiVersion\":\"networking.k8s.io/v1\",\"enabled\":false,\"externalAgents\":{},\"internalAgents\":{\"allowed\":true,\"namespaceLabels\":{},\"podLabels\":{}}},\"persistence\":{\"accessMode\":\"ReadWriteOnce\",\"annotations\":{},\"enabled\":true,\"existingClaim\":null,\"labels\":{},\"mounts\":null,\"size\":\"8Gi\",\"storageClass\":null,\"volumes\":null},\"rbac\":{\"create\":true,\"readSecrets\":false},\"renderHelmLabels\":true,\"serviceAccount\":{\"annotations\":{},\"create\":true,\"extraLabels\":{},\"imagePullSecretName\":null,\"name\":null},\"serviceAccountAgent\":{\"annotations\":{},\"create\":false,\"extraLabels\":{},\"imagePullSecretName\":null,\"name\":null}}",
                "version": "4.3.10"
              }
            ],
            "name": "my-jenkins-release",
            "namespace": "default",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://charts.jenkins.io",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "# Default values for jenkins.\n# This is a YAML-formatted file.\n# Declare name/value pairs to be passed into your templates.\n# name: value\n\n## Overrides for generated resource names\n# See templates/_helpers.tpl\n# nameOverride:\n# fullnameOverride:\n# namespaceOverride:\n\n# For FQDN resolving of the controller service. Change this value to match your existing configuration.\n# ref: https://github.com/kubernetes/dns/blob/master/docs/specification.md\nclusterZone: \"cluster.local\"\n\nrenderHelmLabels: true\n\ncontroller:\n  # Used for label app.kubernetes.io/component\n  componentName: \"jenkins-controller\"\n  image: \"jenkins/jenkins\"\n  # tag: \"2.375.3-jdk11\"\n  tagLabel: jdk11\n  imagePullPolicy: \"Always\"\n  imagePullSecretName:\n  # Optionally configure lifetime for controller-container\n  lifecycle:\n  #  postStart:\n  #    exec:\n  #      command:\n  #      - \"uname\"\n  #      - \"-a\"\n  disableRememberMe: false\n  numExecutors: 0\n  # configures the executor mode of the Jenkins node. Possible values are: NORMAL or EXCLUSIVE\n  executorMode: \"NORMAL\"\n  # This is ignored if enableRawHtmlMarkupFormatter is true\n  markupFormatter: plainText\n  customJenkinsLabels: []\n  # The default configuration uses this secret to configure an admin user\n  # If you don't need that user or use a different security realm then you can disable it\n  adminSecret: true\n\n  hostNetworking: false\n  # When enabling LDAP or another non-Jenkins identity source, the built-in admin account will no longer exist.\n  # If you disable the non-Jenkins identity store and instead use the Jenkins internal one,\n  # you should revert controller.adminUser to your preferred admin user:\n  adminUser: \"admin\"\n  adminPassword: \"admin\"\n  admin:\n    existingSecret: \"\"\n    userKey: jenkins-admin-user\n    passwordKey: jenkins-admin-password\n  # This values should not be changed unless you use your custom image of jenkins or any devired from. If you want to use\n  # Cloudbees Jenkins Distribution docker, you should set jenkinsHome: \"/var/cloudbees-jenkins-distribution\"\n  jenkinsHome: \"/var/jenkins_home\"\n  # This values should not be changed unless you use your custom image of jenkins or any devired from. If you want to use\n  # Cloudbees Jenkins Distribution docker, you should set jenkinsRef: \"/usr/share/cloudbees-jenkins-distribution/ref\"\n  jenkinsRef: \"/usr/share/jenkins/ref\"\n  # Path to the jenkins war file which is used by jenkins-plugin-cli.\n  jenkinsWar: \"/usr/share/jenkins/jenkins.war\"\n  # Overrides the default arguments passed to the war\n  # overrideArgs:\n  #   - --httpPort=8080\n  resources:\n    requests:\n      cpu: \"50m\"\n      memory: \"256Mi\"\n    limits:\n      cpu: \"2000m\"\n      memory: \"4096Mi\"\n  # Overrides the init container default values\n  # initContainerResources:\n  #   requests:\n  #     cpu: \"50m\"\n  #     memory: \"256Mi\"\n  #   limits:\n  #     cpu: \"2000m\"\n  #     memory: \"4096Mi\"\n  # Environment variables that get added to the init container (useful for e.g. http_proxy)\n  # initContainerEnv:\n  #   - name: http_proxy\n  #     value: \"http://192.168.64.1:3128\"\n  # containerEnv:\n  #   - name: http_proxy\n  #     value: \"http://192.168.64.1:3128\"\n  # Set min/max heap here if needed with:\n  # javaOpts: \"-Xms512m -Xmx512m\"\n  # jenkinsOpts: \"\"\n  # If you are using the ingress definitions provided by this chart via the `controller.ingress` block the configured hostname will be the ingress hostname starting with `https://` or `http://` depending on the `tls` configuration.\n  # The Protocol can be overwritten by specifying `controller.jenkinsUrlProtocol`.\n  # jenkinsUrlProtocol: \"https\"\n  # If you are not using the provided ingress you can specify `controller.jenkinsUrl` to change the url definition.\n  # jenkinsUrl: \"\"\n  # If you set this prefix and use ingress controller then you might want to set the ingress path below\n  # jenkinsUriPrefix: \"/jenkins\"\n  # Enable pod security context (must be `true` if podSecurityContextOverride, runAsUser or fsGroup are set)\n  usePodSecurityContext: true\n  # Note that `runAsUser`, `fsGroup`, and `securityContextCapabilities` are\n  # being deprecated and replaced by `podSecurityContextOverride`.\n  # Set runAsUser to 1000 to let Jenkins run as non-root user 'jenkins' which exists in 'jenkins/jenkins' docker image.\n  # When setting runAsUser to a different value than 0 also set fsGroup to the same value:\n  runAsUser: 1000\n  fsGroup: 1000\n  # If you have PodSecurityPolicies that require dropping of capabilities as suggested by CIS K8s benchmark, put them here\n  securityContextCapabilities: {}\n  #  drop:\n  #    - NET_RAW\n  # Completely overwrites the contents of the `securityContext`, ignoring the\n  # values provided for the deprecated fields: `runAsUser`, `fsGroup`, and\n  # `securityContextCapabilities`.  In the case of mounting an ext4 filesystem,\n  # it might be desirable to use `supplementalGroups` instead of `fsGroup` in\n  # the `securityContext` block: https://github.com/kubernetes/kubernetes/issues/67014#issuecomment-589915496\n  # podSecurityContextOverride:\n  #   runAsUser: 1000\n  #   runAsNonRoot: true\n  #   supplementalGroups: [1000]\n  #   # capabilities: {}\n  # Container securityContext\n  containerSecurityContext:\n    runAsUser: 1000\n    runAsGroup: 1000\n    readOnlyRootFilesystem: true\n    allowPrivilegeEscalation: false\n  servicePort: 8080\n  targetPort: 8080\n  # For minikube, set this to NodePort, elsewhere use LoadBalancer\n  # Use ClusterIP if your setup includes ingress controller\n  serviceType: ClusterIP\n  # Use Local to preserve the client source IP and avoids a second hop for LoadBalancer and Nodeport type services,\n  # but risks potentially imbalanced traffic spreading.\n  serviceExternalTrafficPolicy:\n  # Jenkins controller service annotations\n  serviceAnnotations: {}\n  # Jenkins controller custom labels\n  statefulSetLabels: {}\n  #   foo: bar\n  #   bar: foo\n  # Jenkins controller service labels\n  serviceLabels: {}\n  #   service.beta.kubernetes.io/aws-load-balancer-backend-protocol: https\n  # Put labels on Jenkins controller pod\n  podLabels: {}\n  # Used to create Ingress record (should used with ServiceType: ClusterIP)\n  # nodePort: \u003cto set explicitly, choose port between 30000-32767\n  # Enable Kubernetes Startup, Liveness and Readiness Probes\n  # if Startup Probe is supported, enable it too\n  # ~ 2 minutes to allow Jenkins to restart when upgrading plugins. Set ReadinessTimeout to be shorter than LivenessTimeout.\n  healthProbes: true\n  probes:\n    startupProbe:\n      httpGet:\n        path: '{{ default \"\" .Values.controller.jenkinsUriPrefix }}/login'\n        port: http\n      periodSeconds: 10\n      timeoutSeconds: 5\n      failureThreshold: 12\n    livenessProbe:\n      failureThreshold: 5\n      httpGet:\n        path: '{{ default \"\" .Values.controller.jenkinsUriPrefix }}/login'\n        port: http\n      periodSeconds: 10\n      timeoutSeconds: 5\n      # If Startup Probe is not supported on your Kubernetes cluster, you might want to use \"initialDelaySeconds\" instead.\n      # It delays the initial liveness probe while Jenkins is starting\n      # initialDelaySeconds: 60\n    readinessProbe:\n      failureThreshold: 3\n      httpGet:\n        path: '{{ default \"\" .Values.controller.jenkinsUriPrefix }}/login'\n        port: http\n      periodSeconds: 10\n      timeoutSeconds: 5\n      # If Startup Probe is not supported on your Kubernetes cluster, you might want to use \"initialDelaySeconds\" instead.\n      # It delays the initial readyness probe while Jenkins is starting\n      # initialDelaySeconds: 60\n\n  # PodDisruptionBudget config\n  podDisruptionBudget:\n    enabled: false\n    # For Kubernetes v1.5+, use 'policy/v1beta1'\n    # For Kubernetes v1.21+, use 'policy/v1'\n    apiVersion: \"policy/v1beta1\"\n    annotations: {}\n    labels: {}\n    # maxUnavailable: \"0\"\n\n  agentListenerEnabled: true\n  agentListenerPort: 50000\n  agentListenerHostPort:\n  agentListenerNodePort:\n  agentListenerExternalTrafficPolicy:\n  agentListenerLoadBalancerSourceRanges:\n  - 0.0.0.0/0\n  disabledAgentProtocols:\n    - JNLP-connect\n    - JNLP2-connect\n  csrf:\n    defaultCrumbIssuer:\n      enabled: true\n      proxyCompatability: true\n  # Kubernetes service type for the JNLP agent service\n  # agentListenerServiceType is the Kubernetes Service type for the JNLP agent service,\n  # either 'LoadBalancer', 'NodePort', or 'ClusterIP'\n  # Note if you set this to 'LoadBalancer', you *must* define annotations to secure it. By default\n  # this will be an external load balancer and allowing inbound 0.0.0.0/0, a HUGE\n  # security risk:  https://github.com/kubernetes/charts/issues/1341\n  agentListenerServiceType: \"ClusterIP\"\n  # Optionally assign an IP to the LoadBalancer agentListenerService LoadBalancer\n  # GKE users: only regional static IPs will work for Service Load balancer.\n  agentListenerLoadBalancerIP:\n  agentListenerServiceAnnotations: {}\n\n  # Example of 'LoadBalancer' type of agent listener with annotations securing it\n  # agentListenerServiceType: LoadBalancer\n  # agentListenerServiceAnnotations:\n  #   service.beta.kubernetes.io/aws-load-balancer-internal: \"True\"\n  #   service.beta.kubernetes.io/load-balancer-source-ranges: \"172.0.0.0/8, 10.0.0.0/8\"\n\n  # LoadBalancerSourcesRange is a list of allowed CIDR values, which are combined with ServicePort to\n  # set allowed inbound rules on the security group assigned to the controller load balancer\n  loadBalancerSourceRanges:\n  - 0.0.0.0/0\n  # Optionally assign a known public LB IP\n  # loadBalancerIP: 1.2.3.4\n  # Optionally configure a JMX port\n  # requires additional javaOpts, ie\n  # javaOpts: \u003e\n  #   -Dcom.sun.management.jmxremote.port=4000\n  #   -Dcom.sun.management.jmxremote.authenticate=false\n  #   -Dcom.sun.management.jmxremote.ssl=false\n  # jmxPort: 4000\n  # Optionally configure other ports to expose in the controller container\n  extraPorts: []\n  # - name: BuildInfoProxy\n  #   port: 9000\n  #   targetPort: 9010 (Optional: Use to explicitly set targetPort if different from port)\n\n  # List of plugins to be install during Jenkins controller start\n  installPlugins:\n    - kubernetes:3734.v562b_b_a_627ea_c\n    - workflow-aggregator:590.v6a_d052e5a_a_b_5\n    - git:4.13.0\n    - configuration-as-code:1569.vb_72405b_80249\n\n  # Set to false to download the minimum required version of all dependencies.\n  installLatestPlugins: true\n\n  # Set to true to download latest dependencies of any plugin that is requested to have the latest version.\n  installLatestSpecifiedPlugins: false\n\n  # List of plugins to install in addition to those listed in controller.installPlugins\n  additionalPlugins: []\n\n  # Enable to initialize the Jenkins controller only once on initial installation.\n  # Without this, whenever the controller gets restarted (Evicted, etc.) it will fetch plugin updates which has the potential to cause breakage.\n  # Note that for this to work, `persistence.enabled` needs to be set to `true`\n  initializeOnce: false\n\n  # Enable to always override the installed plugins with the values of 'controller.installPlugins' on upgrade or redeployment.\n  # overwritePlugins: true\n\n  # Configures if plugins bundled with `controller.image` should be overwritten with the values of 'controller.installPlugins' on upgrade or redeployment.\n  overwritePluginsFromImage: true\n\n  # Configures the restrictions for naming projects. Set this key to null or empty to skip it in the default config.\n  projectNamingStrategy: standard\n\n  # Enable HTML parsing using OWASP Markup Formatter Plugin (antisamy-markup-formatter), useful with ghprb plugin.\n  # The plugin is not installed by default, please update controller.installPlugins.\n  enableRawHtmlMarkupFormatter: false\n  # Used to approve a list of groovy functions in pipelines used the script-security plugin. Can be viewed under /scriptApproval\n  scriptApproval: []\n  #  - \"method groovy.json.JsonSlurperClassic parseText java.lang.String\"\n  #  - \"new groovy.json.JsonSlurperClassic\"\n  # List of groovy init scripts to be executed during Jenkins controller start\n  initScripts: []\n  #  - |\n  #    print 'adding global pipeline libraries, register properties, bootstrap jobs...'\n\n  # 'name' is a name of an existing secret in same namespace as jenkins,\n  # 'keyName' is the name of one of the keys inside current secret.\n  # the 'name' and 'keyName' are concatenated with a '-' in between, so for example:\n  # an existing secret \"secret-credentials\" and a key inside it named \"github-password\" should be used in Jcasc as ${secret-credentials-github-password}\n  # 'name' and 'keyName' must be lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-',\n  # and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc')\n  # existingSecret existing secret \"secret-credentials\" and a key inside it named \"github-username\" should be used in Jcasc as ${github-username}\n  # When using existingSecret no need to specify the keyName under additionalExistingSecrets.\n  existingSecret:\n\n  additionalExistingSecrets: []\n  #  - name: secret-name-1\n  #    keyName: username\n  #  - name: secret-name-1\n  #    keyName: password\n\n  additionalSecrets: []\n  #  - name: nameOfSecret\n  #    value: secretText\n\n  # Generate SecretClaim resources in order to create Kubernetes secrets from HashiCorp Vault using kube-vault-controller.\n  # 'name' is name of the secret that will be created in Kubernetes. The Jenkins fullname is prepended to this value.\n  # 'path' is the fully qualified path to the secret in Vault\n  # 'type' is an optional Kubernetes secret type. Defaults to 'Opaque'\n  # 'renew' is an optional secret renewal time in seconds\n  secretClaims: []\n  # - name: secretName        # required\n  #   path: testPath          # required\n  #   type: kubernetes.io/tls # optional\n  #   renew: 60               # optional\n\n  # Name of default cloud configuration.\n  cloudName: \"kubernetes\"\n\n  # Below is the implementation of Jenkins Configuration as Code.  Add a key under configScripts for each configuration area,\n  # where each corresponds to a plugin or section of the UI.  Each key (prior to | character) is just a label, and can be any value.\n  # Keys are only used to give the section a meaningful name.  The only restriction is they may only contain RFC 1123 \\ DNS label\n  # characters: lowercase letters, numbers, and hyphens.  The keys become the name of a configuration yaml file on the controller in\n  # /var/jenkins_home/casc_configs (by default) and will be processed by the Configuration as Code Plugin.  The lines after each |\n  # become the content of the configuration yaml file.  The first line after this is a JCasC root element, eg jenkins, credentials,\n  # etc.  Best reference is https://\u003cjenkins_url\u003e/configuration-as-code/reference.  The example below creates a welcome message:\n  JCasC:\n    defaultConfig: true\n    configUrls: []\n    # - https://acme.org/jenkins.yaml\n    # Remote URL:s for configuration files.\n    configScripts: {}\n    #  welcome-message: |\n    #    jenkins:\n    #      systemMessage: Welcome to our CI\\CD server.  This Jenkins is configured and managed 'as code'.\n    # Allows adding to the top-level security JCasC section. For legacy,  default the chart includes apiToken configurations\n    security:\n      apiToken:\n        creationOfLegacyTokenEnabled: false\n        tokenGenerationOnCreationEnabled: false\n        usageStatisticsEnabled: true\n    # Ignored if securityRealm is defined in controller.JCasC.configScripts\n    securityRealm: |-\n      local:\n        allowsSignup: false\n        enableCaptcha: false\n        users:\n        - id: \"${chart-admin-username}\"\n          name: \"Jenkins Admin\"\n          password: \"${chart-admin-password}\"\n    # Ignored if authorizationStrategy is defined in controller.JCasC.configScripts\n    authorizationStrategy: |-\n      loggedInUsersCanDoAnything:\n        allowAnonymousRead: false\n  # Optionally specify additional init-containers\n  customInitContainers: []\n  # - name: custom-init\n  #   image: \"alpine:3.7\"\n  #   imagePullPolicy: Always\n  #   command: [ \"uname\", \"-a\" ]\n\n  sidecars:\n    configAutoReload:\n      # If enabled: true, Jenkins Configuration as Code will be reloaded on-the-fly without a reboot.  If false or not-specified,\n      # jcasc changes will cause a reboot and will only be applied at the subsequent start-up.  Auto-reload uses the\n      # http://\u003cjenkins_url\u003e/reload-configuration-as-code endpoint to reapply config when changes to the configScripts are detected.\n      enabled: true\n      image: kiwigrid/k8s-sidecar:1.15.0\n      imagePullPolicy: IfNotPresent\n      resources: {}\n        #   limits:\n        #     cpu: 100m\n        #     memory: 100Mi\n        #   requests:\n        #     cpu: 50m\n        #     memory: 50Mi\n      # How many connection-related errors to retry on\n      reqRetryConnect: 10\n      # env:\n      #   - name: REQ_TIMEOUT\n      #     value: \"30\"\n      # SSH port value can be set to any unused TCP port.  The default, 1044, is a non-standard SSH port that has been chosen at random.\n      # Is only used to reload jcasc config from the sidecar container running in the Jenkins controller pod.\n      # This TCP port will not be open in the pod (unless you specifically configure this), so Jenkins will not be\n      # accessible via SSH from outside of the pod.  Note if you use non-root pod privileges (runAsUser \u0026 fsGroup),\n      # this must be \u003e 1024:\n      sshTcpPort: 1044\n      # folder in the pod that should hold the collected dashboards:\n      folder: \"/var/jenkins_home/casc_configs\"\n      # If specified, the sidecar will search for JCasC config-maps inside this namespace.\n      # Otherwise the namespace in which the sidecar is running will be used.\n      # It's also possible to specify ALL to search in all namespaces:\n      # searchNamespace:\n      containerSecurityContext:\n        readOnlyRootFilesystem: true\n        allowPrivilegeEscalation: false\n\n    # Allows you to inject additional/other sidecars\n    other: []\n    ## The example below runs the client for https://smee.io as sidecar container next to Jenkins,\n    ## that allows to trigger build behind a secure firewall.\n    ## https://jenkins.io/blog/2019/01/07/webhook-firewalls/#triggering-builds-with-webhooks-behind-a-secure-firewall\n    ##\n    ## Note: To use it you should go to https://smee.io/new and update the url to the generete one.\n    # - name: smee\n    #   image: docker.io/twalter/smee-client:1.0.2\n    #   args: [\"--port\", \"{{ .Values.controller.servicePort }}\", \"--path\", \"/github-webhook/\", \"--url\", \"https://smee.io/new\"]\n    #   resources:\n    #     limits:\n    #       cpu: 50m\n    #       memory: 128Mi\n    #     requests:\n    #       cpu: 10m\n    #       memory: 32Mi\n  # Name of the Kubernetes scheduler to use\n  schedulerName: \"\"\n  # Node labels and tolerations for pod assignment\n  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector\n  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#taints-and-tolerations-beta-feature\n  nodeSelector: {}\n\n  terminationGracePeriodSeconds:\n\n  terminationMessagePath:\n  terminationMessagePolicy:\n\n  tolerations: []\n\n  affinity: {}\n  # Leverage a priorityClass to ensure your pods survive resource shortages\n  # ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/\n  priorityClassName:\n\n  podAnnotations: {}\n  # Add StatefulSet annotations\n  statefulSetAnnotations: {}\n\n  # StatefulSet updateStrategy\n  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies\n  updateStrategy: {}\n\n  ingress:\n    enabled: false\n    # Override for the default paths that map requests to the backend\n    paths: []\n    # - backend:\n    #     serviceName: ssl-redirect\n    #     servicePort: use-annotation\n    # - backend:\n    #     serviceName: \u003e-\n    #       {{ template \"jenkins.fullname\" . }}\n    #     # Don't use string here, use only integer value!\n    #     servicePort: 8080\n    # For Kubernetes v1.14+, use 'networking.k8s.io/v1beta1'\n    # For Kubernetes v1.19+, use 'networking.k8s.io/v1'\n    apiVersion: \"extensions/v1beta1\"\n    labels: {}\n    annotations: {}\n    # kubernetes.io/ingress.class: nginx\n    # kubernetes.io/tls-acme: \"true\"\n    # For Kubernetes \u003e= 1.18 you should specify the ingress-controller via the field ingressClassName\n    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress\n    # ingressClassName: nginx\n    # Set this path to jenkinsUriPrefix above or use annotations to rewrite path\n    # path: \"/jenkins\"\n    # configures the hostname e.g. jenkins.example.com\n    hostName:\n    tls:\n    # - secretName: jenkins.cluster.local\n    #   hosts:\n    #     - jenkins.cluster.local\n\n  # often you want to have your controller all locked down and private\n  # but you still want to get webhooks from your SCM\n  # A secondary ingress will let you expose different urls\n  # with a differnt configuration\n  secondaryingress:\n    enabled: false\n    # paths you want forwarded to the backend\n    # ex /github-webhook\n    paths: []\n    # For Kubernetes v1.14+, use 'networking.k8s.io/v1beta1'\n    # For Kubernetes v1.19+, use 'networking.k8s.io/v1'\n    apiVersion: \"extensions/v1beta1\"\n    labels: {}\n    annotations: {}\n    # kubernetes.io/ingress.class: nginx\n    # kubernetes.io/tls-acme: \"true\"\n    # For Kubernetes \u003e= 1.18 you should specify the ingress-controller via the field ingressClassName\n    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress\n    # ingressClassName: nginx\n    # configures the hostname e.g. jenkins-external.example.com\n    hostName:\n    tls:\n    # - secretName: jenkins-external.example.com\n    #   hosts:\n    #     - jenkins-external.example.com\n\n  # If you're running on GKE and need to configure a backendconfig\n  # to finish ingress setup, use the following values.\n  # Docs: https://cloud.google.com/kubernetes-engine/docs/concepts/backendconfig\n  backendconfig:\n    enabled: false\n    apiVersion: \"extensions/v1beta1\"\n    name:\n    labels: {}\n    annotations: {}\n    spec: {}\n\n  # Openshift route\n  route:\n    enabled: false\n    labels: {}\n    annotations: {}\n    # path: \"/jenkins\"\n\n  # controller.hostAliases allows for adding entries to Pod /etc/hosts:\n  # https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/\n  hostAliases: []\n  # - ip: 192.168.50.50\n  #   hostnames:\n  #     - something.local\n  # - ip: 10.0.50.50\n  #   hostnames:\n  #     - other.local\n\n  # Expose Prometheus metrics\n  prometheus:\n    # If enabled, add the prometheus plugin to the list of plugins to install\n    # https://plugins.jenkins.io/prometheus\n    enabled: false\n    # Additional labels to add to the ServiceMonitor object\n    serviceMonitorAdditionalLabels: {}\n    # Set a custom namespace where to deploy ServiceMonitor resource\n    # serviceMonitorNamespace: monitoring\n    scrapeInterval: 60s\n    # This is the default endpoint used by the prometheus plugin\n    scrapeEndpoint: /prometheus\n    # Additional labels to add to the PrometheusRule object\n    alertingRulesAdditionalLabels: {}\n    # An array of prometheus alerting rules\n    # See here: https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/\n    # The `groups` root object is added by default, simply add the rule entries\n    alertingrules: []\n    # Set a custom namespace where to deploy PrometheusRule resource\n    prometheusRuleNamespace: \"\"\n\n    # RelabelConfigs to apply to samples before scraping. Prometheus Operator automatically adds\n    # relabelings for a few standard Kubernetes fields. The original scrape jobâ€™s name\n    # is available via the __tmp_prometheus_job_name label.\n    # More info: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config\n    relabelings: []\n    # MetricRelabelConfigs to apply to samples before ingestion.\n    metricRelabelings: []\n\n  googlePodMonitor:\n    # If enabled, It creates Google Managed Prometheus scraping config\n    enabled: false\n    # Set a custom namespace where to deploy PodMonitoring resource\n    # serviceMonitorNamespace: \"\"\n    scrapeInterval: 60s\n    # This is the default endpoint used by the prometheus plugin\n    scrapeEndpoint: /prometheus\n\n  # Can be used to disable rendering controller test resources when using helm template\n  testEnabled: true\n\n  httpsKeyStore:\n    jenkinsHttpsJksSecretName: ''\n    enable: false\n    httpPort: 8081\n    path: \"/var/jenkins_keystore\"\n    fileName: \"keystore.jks\"\n    password: \"password\"\n    # Convert keystore.jks files content to base64 ( cat keystore.jks | base64 ) and put the output here\n    jenkinsKeyStoreBase64Encoded: |\n        /u3+7QAAAAIAAAABAAAAAQANamVua2luc2NpLmNvbQAAAW2r/b1ZAAAFATCCBP0wDgYKKwYBBAEq\n        AhEBAQUABIIE6QbCqasvoHS0pSwYqSvdydMCB9t+VNfwhFIiiuAelJfO5sSe2SebJbtwHgLcRz1Z\n        gMtWgOSFdl3bWSzA7vrW2LED52h+jXLYSWvZzuDuh8hYO85m10ikF6QR+dTi4jra0whIFDvq3pxe\n        TnESxEsN+DvbZM3jA3qsjQJSeISNpDjO099dqQvHpnCn18lyk7J4TWJ8sOQQb1EM2zDAfAOSqA/x\n        QuPEFl74DlY+5DIk6EBvpmWhaMSvXzWZACGA0sYqa157dq7O0AqmuLG/EI5EkHETO4CrtBW+yLcy\n        2dUCXOMA+j+NjM1BjrQkYE5vtSfNO6lFZcISyKo5pTFlcA7ut0Fx2nZ8GhHTn32CpeWwNcZBn1gR\n        pZVt6DxVVkhTAkMLhR4rL2wGIi/1WRs23ZOLGKtyDNvDHnQyDiQEoJGy9nAthA8aNHa3cfdF10vB\n        Drb19vtpFHmpvKEEhpk2EBRF4fTi644Fuhu2Ied6118AlaPvEea+n6G4vBz+8RWuVCmZjLU+7h8l\n        Hy3/WdUPoIL5eW7Kz+hS+sRTFzfu9C48dMkQH3a6f3wSY+mufizNF9U298r98TnYy+PfDJK0bstG\n        Ph6yPWx8DGXKQBwrhWJWXI6JwZDeC5Ny+l8p1SypTmAjpIaSW3ge+KgcL6Wtt1R5hUV1ajVwVSUi\n        HF/FachKqPqyLJFZTGjNrxnmNYpt8P1d5JTvJfmfr55Su/P9n7kcyWp7zMcb2Q5nlXt4tWogOHLI\n        OzEWKCacbFfVHE+PpdrcvCVZMDzFogIq5EqGTOZe2poPpBVE+1y9mf5+TXBegy5HToLWvmfmJNTO\n        NCDuBjgLs2tdw2yMPm4YEr57PnMX5gGTC3f2ZihXCIJDCRCdQ9sVBOjIQbOCzxFXkVITo0BAZhCi\n        Yz61wt3Ud8e//zhXWCkCsSV+IZCxxPzhEFd+RFVjW0Nm9hsb2FgAhkXCjsGROgoleYgaZJWvQaAg\n        UyBzMmKDPKTllBHyE3Gy1ehBNGPgEBChf17/9M+j8pcm1OmlM434ctWQ4qW7RU56//yq1soFY0Te\n        fu2ei03a6m68fYuW6s7XEEK58QisJWRAvEbpwu/eyqfs7PsQ+zSgJHyk2rO95IxdMtEESb2GRuoi\n        Bs+AHNdYFTAi+GBWw9dvEgqQ0Mpv0//6bBE/Fb4d7b7f56uUNnnE7mFnjGmGQN+MvC62pfwfvJTT\n        EkT1iZ9kjM9FprTFWXT4UmO3XTvesGeE50sV9YPm71X4DCQwc4KE8vyuwj0s6oMNAUACW2ClU9QQ\n        y0tRpaF1tzs4N42Q5zl0TzWxbCCjAtC3u6xf+c8MCGrr7DzNhm42LOQiHTa4MwX4x96q7235oiAU\n        iQqSI/hyF5yLpWw4etyUvsx2/0/0wkuTU1FozbLoCWJEWcPS7QadMrRRISxHf0YobIeQyz34regl\n        t1qSQ3dCU9D6AHLgX6kqllx4X0fnFq7LtfN7fA2itW26v+kAT2QFZ3qZhINGfofCja/pITC1uNAZ\n        gsJaTMcQ600krj/ynoxnjT+n1gmeqThac6/Mi3YlVeRtaxI2InL82ZuD+w/dfY9OpPssQjy3xiQa\n        jPuaMWXRxz/sS9syOoGVH7XBwKrWpQcpchozWJt40QV5DslJkclcr8aC2AGlzuJMTdEgz1eqV0+H\n        bAXG9HRHN/0eJTn1/QAAAAEABVguNTA5AAADjzCCA4swggJzAhRGqVxH4HTLYPGO4rzHcCPeGDKn\n        xTANBgkqhkiG9w0BAQsFADCBgTELMAkGA1UEBhMCY2ExEDAOBgNVBAgMB29udGFyaW8xEDAOBgNV\n        BAcMB3Rvcm9udG8xFDASBgNVBAoMC2plbmtpbnN0ZXN0MRkwFwYDVQQDDBBqZW5raW5zdGVzdC5p\n        bmZvMR0wGwYJKoZIhvcNAQkBFg50ZXN0QHRlc3QuaW5mbzAeFw0xOTEwMDgxNTI5NTVaFw0xOTEx\n        MDcxNTI5NTVaMIGBMQswCQYDVQQGEwJjYTEQMA4GA1UECAwHb250YXJpbzEQMA4GA1UEBwwHdG9y\n        b250bzEUMBIGA1UECgwLamVua2luc3Rlc3QxGTAXBgNVBAMMEGplbmtpbnN0ZXN0LmluZm8xHTAb\n        BgkqhkiG9w0BCQEWDnRlc3RAdGVzdC5pbmZvMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKC\n        AQEA02q352JTHGvROMBhSHvSv+vnoOTDKSTz2aLQn0tYrIRqRo+8bfmMjXuhkwZPSnCpvUGNAJ+w\n        Jrt/dqMoYUjCBkjylD/qHmnXN5EwS1cMg1Djh65gi5JJLFJ7eNcoSsr/0AJ+TweIal1jJSP3t3PF\n        9Uv21gm6xdm7HnNK66WpUUXLDTKaIs/jtagVY1bLOo9oEVeLN4nT2CYWztpMvdCyEDUzgEdDbmrP\n        F5nKUPK5hrFqo1Dc5rUI4ZshL3Lpv398aMxv6n2adQvuL++URMEbXXBhxOrT6rCtYzbcR5fkwS9i\n        d3Br45CoWOQro02JAepoU0MQKY5+xQ4Bq9Q7tB9BAwIDAQABMA0GCSqGSIb3DQEBCwUAA4IBAQAe\n        4xc+mSvKkrKBHg9/zpkWgZUiOp4ENJCi8H4tea/PCM439v6y/kfjT/okOokFvX8N5aa1OSz2Vsrl\n        m8kjIc6hiA7bKzT6lb0EyjUShFFZ5jmGVP4S7/hviDvgB5yEQxOPpumkdRP513YnEGj/o9Pazi5h\n        /MwpRxxazoda9r45kqQpyG+XoM4pB+Fd3JzMc4FUGxfVPxJU4jLawnJJiZ3vqiSyaB0YyUL+Er1Q\n        6NnqtR4gEBF0ZVlQmkycFvD4EC2boP943dLqNUvop+4R3SM1QMM6P5u8iTXtHd/VN4MwMyy1wtog\n        hYAzODo1Jt59pcqqKJEas0C/lFJEB3frw4ImNx5fNlJYOpx+ijfQs9m39CevDq0=\n\nagent:\n  enabled: true\n  defaultsProviderTemplate: \"\"\n  # URL for connecting to the Jenkins contoller\n  jenkinsUrl:\n  # connect to the specified host and port, instead of connecting directly to the Jenkins controller\n  jenkinsTunnel:\n  kubernetesConnectTimeout: 5\n  kubernetesReadTimeout: 15\n  maxRequestsPerHostStr: \"32\"\n  namespace:\n  image: \"jenkins/inbound-agent\"\n  tag: \"4.11.2-4\"\n  workingDir: \"/home/jenkins/agent\"\n  nodeUsageMode: \"NORMAL\"\n  customJenkinsLabels: []\n  # name of the secret to be used for image pulling\n  imagePullSecretName:\n  componentName: \"jenkins-agent\"\n  websocket: false\n  privileged: false\n  runAsUser:\n  runAsGroup:\n  hostNetworking: false\n  resources:\n    requests:\n      cpu: \"512m\"\n      memory: \"512Mi\"\n    limits:\n      cpu: \"512m\"\n      memory: \"512Mi\"\n  # You may want to change this to true while testing a new image\n  alwaysPullImage: false\n  # Controls how agent pods are retained after the Jenkins build completes\n  # Possible values: Always, Never, OnFailure\n  podRetention: \"Never\"\n  # Disable if you do not want the Yaml the agent pod template to show up\n  # in the job Console Output. This can be helpful for either security reasons\n  # or simply to clean up the output to make it easier to read.\n  showRawYaml: true\n  # You can define the volumes that you want to mount for this container\n  # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, PVC, Secret\n  # Configure the attributes as they appear in the corresponding Java class for that type\n  # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes\n  volumes: []\n  # - type: ConfigMap\n  #   configMapName: myconfigmap\n  #   mountPath: /var/myapp/myconfigmap\n  # - type: EmptyDir\n  #   mountPath: /var/myapp/myemptydir\n  #   memory: false\n  # - type: HostPath\n  #   hostPath: /var/lib/containers\n  #   mountPath: /var/myapp/myhostpath\n  # - type: Nfs\n  #   mountPath: /var/myapp/mynfs\n  #   readOnly: false\n  #   serverAddress: \"192.0.2.0\"\n  #   serverPath: /var/lib/containers\n  # - type: PVC\n  #   claimName: mypvc\n  #   mountPath: /var/myapp/mypvc\n  #   readOnly: false\n  # - type: Secret\n  #   defaultMode: \"600\"\n  #   mountPath: /var/myapp/mysecret\n  #   secretName: mysecret\n  # Pod-wide environment, these vars are visible to any container in the agent pod\n\n  # You can define the workspaceVolume that you want to mount for this container\n  # Allowed types are: DynamicPVC, EmptyDir, HostPath, Nfs, PVC\n  # Configure the attributes as they appear in the corresponding Java class for that type\n  # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes/workspace\n  workspaceVolume: {}\n  ## DynamicPVC example\n  # type: DynamicPVC\n  # configMapName: myconfigmap\n  ## EmptyDir example\n  # type: EmptyDir\n  # memory: false\n  ## HostPath example\n  # type: HostPath\n  # hostPath: /var/lib/containers\n  ## NFS example\n  # type: Nfs\n  # readOnly: false\n  # serverAddress: \"192.0.2.0\"\n  # serverPath: /var/lib/containers\n  ## PVC example\n  # type: PVC\n  # claimName: mypvc\n  # readOnly: false\n  #\n  # Pod-wide environment, these vars are visible to any container in the agent pod\n  envVars: []\n  # - name: PATH\n  #   value: /usr/local/bin\n  # Mount a secret as environment variable\n  secretEnvVars: []\n  # - key: PATH\n  #   optional: false # default: false\n  #   secretKey: MY-K8S-PATH\n  #   secretName: my-k8s-secret\n  nodeSelector: {}\n  # Key Value selectors. Ex:\n  # jenkins-agent: v1\n\n  # Executed command when side container gets started\n  command:\n  args: \"${computer.jnlpmac} ${computer.name}\"\n  # Side container name\n  sideContainerName: \"jnlp\"\n  # Doesn't allocate pseudo TTY by default\n  TTYEnabled: false\n  # Max number of spawned agent\n  containerCap: 10\n  # Pod name\n  podName: \"default\"\n  # Allows the Pod to remain active for reuse until the configured number of\n  # minutes has passed since the last step was executed on it.\n  idleMinutes: 0\n  # Raw yaml template for the Pod. For example this allows usage of toleration for agent pods.\n  # https://github.com/jenkinsci/kubernetes-plugin#using-yaml-to-define-pod-templates\n  # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n  yamlTemplate: \"\"\n  # yamlTemplate: |-\n  #   apiVersion: v1\n  #   kind: Pod\n  #   spec:\n  #     tolerations:\n  #     - key: \"key\"\n  #       operator: \"Equal\"\n  #       value: \"value\"\n  # Defines how the raw yaml field gets merged with yaml definitions from inherited pod templates: merge or override\n  yamlMergeStrategy: \"override\"\n  # Timeout in seconds for an agent to be online\n  connectTimeout: 100\n  # Annotations to apply to the pod.\n  annotations: {}\n\n  # Add additional containers to the agents.\n  # Containers specified here are added to all agents. Set key empty to remove container from additional agents.\n  additionalContainers: []\n  #  - sideContainerName: dind\n  #    image: docker\n  #    tag: dind\n  #    command: dockerd-entrypoint.sh\n  #    args: \"\"\n  #    privileged: true\n  #    resources:\n  #      requests:\n  #        cpu: 500m\n  #        memory: 1Gi\n  #      limits:\n  #        cpu: 1\n  #        memory: 2Gi\n\n  # Disable the default Jenkins Agent configuration.\n  # Useful when configuring agents only with the podTemplates value, since the default podTemplate populated by values mentioned above will be excluded in the rendered template.\n  disableDefaultAgent: false\n\n  # Below is the implementation of custom pod templates for the default configured kubernetes cloud.\n  # Add a key under podTemplates for each pod template. Each key (prior to | character) is just a label, and can be any value.\n  # Keys are only used to give the pod template a meaningful name.  The only restriction is they may only contain RFC 1123 \\ DNS label\n  # characters: lowercase letters, numbers, and hyphens. Each pod template can contain multiple containers.\n  # For this pod templates configuration to be loaded the following values must be set:\n  # controller.JCasC.defaultConfig: true\n  # Best reference is https://\u003cjenkins_url\u003e/configuration-as-code/reference#Cloud-kubernetes. The example below creates a python pod template.\n  podTemplates: {}\n  #  python: |\n  #    - name: python\n  #      label: jenkins-python\n  #      serviceAccount: jenkins\n  #      containers:\n  #        - name: python\n  #          image: python:3\n  #          command: \"/bin/sh -c\"\n  #          args: \"cat\"\n  #          ttyEnabled: true\n  #          privileged: true\n  #          resourceRequestCpu: \"400m\"\n  #          resourceRequestMemory: \"512Mi\"\n  #          resourceLimitCpu: \"1\"\n  #          resourceLimitMemory: \"1024Mi\"\n\n# Here you can add additional agents\n# They inherit all values from `agent` so you only need to specify values which differ\nadditionalAgents: {}\n#  maven:\n#    podName: maven\n#    customJenkinsLabels: maven\n#    # An example of overriding the jnlp container\n#    # sideContainerName: jnlp\n#    image: jenkins/jnlp-agent-maven\n#    tag: latest\n#  python:\n#    podName: python\n#    customJenkinsLabels: python\n#    sideContainerName: python\n#    image: python\n#    tag: \"3\"\n#    command: \"/bin/sh -c\"\n#    args: \"cat\"\n#    TTYEnabled: true\n\npersistence:\n  enabled: true\n  ## A manually managed Persistent Volume and Claim\n  ## Requires persistence.enabled: true\n  ## If defined, PVC must be created manually before volume will be bound\n  existingClaim:\n  ## jenkins data Persistent Volume Storage Class\n  ## If defined, storageClassName: \u003cstorageClass\u003e\n  ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n  ## If undefined (the default) or set to null, no storageClassName spec is\n  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n  ##   GKE, AWS \u0026 OpenStack)\n  ##\n  storageClass:\n  annotations: {}\n  labels: {}\n  accessMode: \"ReadWriteOnce\"\n  size: \"8Gi\"\n  volumes:\n  #  - name: nothing\n  #    emptyDir: {}\n  mounts:\n  #  - mountPath: /var/nothing\n  #    name: nothing\n  #    readOnly: true\n\nnetworkPolicy:\n  # Enable creation of NetworkPolicy resources.\n  enabled: false\n  # For Kubernetes v1.4, v1.5 and v1.6, use 'extensions/v1beta1'\n  # For Kubernetes v1.7, use 'networking.k8s.io/v1'\n  apiVersion: networking.k8s.io/v1\n  # You can allow agents to connect from both within the cluster (from within specific/all namespaces) AND/OR from a given external IP range\n  internalAgents:\n    allowed: true\n    podLabels: {}\n    namespaceLabels: {}\n      # project: myproject\n  externalAgents: {}\n  #   ipCIDR: 172.17.0.0/16\n  #   except:\n  #     - 172.17.1.0/24\n\n## Install Default RBAC roles and bindings\nrbac:\n  create: true\n  readSecrets: false\n\nserviceAccount:\n  create: true\n  # The name of the service account is autogenerated by default\n  name:\n  annotations: {}\n  extraLabels: {}\n  imagePullSecretName:\n\n\nserviceAccountAgent:\n  # Specifies whether a ServiceAccount should be created\n  create: false\n  # The name of the ServiceAccount to use.\n  # If not set and create is true, a name is generated using the fullname template\n  name:\n  annotations: {}\n  extraLabels: {}\n  imagePullSecretName:\n\n## Backup cronjob configuration\n## Ref: https://github.com/maorfr/kube-tasks\nbackup:\n  # Backup must use RBAC\n  # So by enabling backup you are enabling RBAC specific for backup\n  enabled: false\n  # Used for label app.kubernetes.io/component\n  componentName: \"backup\"\n  # Schedule to run jobs. Must be in cron time format\n  # Ref: https://crontab.guru/\n  schedule: \"0 2 * * *\"\n  labels: {}\n  serviceAccount:\n    create: true\n    name:\n    annotations: {}\n    # Example for authorization to AWS S3 using kube2iam or IRSA\n    # Can also be done using environment variables\n    # iam.amazonaws.com/role: \"jenkins\"\n    # \"eks.amazonaws.com/role-arn\": \"arn:aws:iam::123456789012:role/jenkins-backup\"\n  # Set this to terminate the job that is running/failing continously and set the job status to \"Failed\"\n  activeDeadlineSeconds: \"\"\n  image:\n    repository: \"maorfr/kube-tasks\"\n    tag: \"0.2.0\"\n  imagePullSecretName:\n  # Additional arguments for kube-tasks\n  # Ref: https://github.com/maorfr/kube-tasks#simple-backup\n  extraArgs: []\n  # Add existingSecret for AWS credentials\n  existingSecret: {}\n  ## Example for using an existing secret\n   # jenkinsaws:\n  ## Use this key for AWS access key ID\n     # awsaccesskey: jenkins_aws_access_key\n  ## Use this key for AWS secret access key\n     # awssecretkey: jenkins_aws_secret_key\n  # Add additional environment variables\n   # jenkinsgcp:\n  ## Use this key for GCP credentials\n     # gcpcredentials: credentials.json\n  env: []\n  # Example environment variable required for AWS credentials chain\n  # - name: \"AWS_REGION\"\n  #   value: \"us-east-1\"\n  resources:\n    requests:\n      memory: 1Gi\n      cpu: 1\n    limits:\n      memory: 1Gi\n      cpu: 1\n  # Destination to store the backup artifacts\n  # Supported cloud storage services: AWS S3, Minio S3, Azure Blob Storage, Google Cloud Storage\n  # Additional support can added. Visit this repository for details\n  # Ref: https://github.com/maorfr/skbn\n  destination: \"s3://jenkins-data/backup\"\n  # By enabling only the jenkins_home/jobs folder gets backed up, not the whole jenkins instance\n  onlyJobs: false\n  # Enable backup pod security context (must be `true` if runAsUser or fsGroup are set)\n  usePodSecurityContext: true\n  # When setting runAsUser to a different value than 0 also set fsGroup to the same value:\n  runAsUser: 1000\n  fsGroup: 1000\n  securityContextCapabilities: {}\n  #  drop:\n  #    - NET_RAW\ncronJob:\n  apiVersion: batch/v1\n\ncheckDeprecation: true\n\nawsSecurityGroupPolicies:\n  enabled: false\n  policies:\n    - name: \"\"\n      securityGroupIds: []\n      podSelector: {}\n\n"
            ],
            "verify": false,
            "version": "4.3.10",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "rabbitmq",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "rabbitmq",
            "cleanup_on_fail": false,
            "create_namespace": false,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "my-rabbitmq-release",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "3.11.11",
                "chart": "rabbitmq",
                "name": "my-rabbitmq-release",
                "namespace": "default",
                "revision": 8,
                "values": "{\"advancedConfiguration\":\"\",\"advancedConfigurationExistingSecret\":\"\",\"affinity\":{},\"args\":[],\"auth\":{\"enableLoopbackUser\":false,\"erlangCookie\":\"\",\"existingErlangSecret\":\"\",\"existingPasswordSecret\":\"\",\"password\":\"\",\"securePassword\":true,\"tls\":{\"autoGenerated\":false,\"caCertificate\":\"\",\"enabled\":false,\"existingSecret\":\"\",\"existingSecretFullChain\":false,\"failIfNoPeerCert\":true,\"overrideCaCertificate\":\"\",\"serverCertificate\":\"\",\"serverKey\":\"\",\"sslOptionsPassword\":{\"enabled\":false,\"existingSecret\":\"\",\"key\":\"\",\"password\":\"\"},\"sslOptionsVerify\":\"verify_peer\"},\"username\":\"user\"},\"clusterDomain\":\"cluster.local\",\"clustering\":{\"addressType\":\"hostname\",\"enabled\":true,\"forceBoot\":false,\"partitionHandling\":\"autoheal\",\"rebalance\":false},\"command\":[],\"commonAnnotations\":{},\"commonLabels\":{},\"communityPlugins\":\"\",\"configuration\":\"## Username and password\\n##\\ndefault_user = {{ .Values.auth.username }}\\n{{- if and (not .Values.auth.securePassword) .Values.auth.password }}\\ndefault_pass = {{ .Values.auth.password }}\\n{{- end }}\\n{{- if .Values.clustering.enabled }}\\n## Clustering\\n##\\ncluster_formation.peer_discovery_backend  = rabbit_peer_discovery_k8s\\ncluster_formation.k8s.host = kubernetes.default\\ncluster_formation.node_cleanup.interval = 10\\ncluster_formation.node_cleanup.only_log_warning = true\\ncluster_partition_handling = {{ .Values.clustering.partitionHandling }}\\n{{- end }}\\n{{- if .Values.loadDefinition.enabled }}\\nload_definitions = {{ .Values.loadDefinition.file }}\\n{{- end }}\\n# queue master locator\\nqueue_master_locator = min-masters\\n# enable loopback user\\n{{- if not (empty .Values.auth.username) }}\\nloopback_users.{{ .Values.auth.username }} = {{ .Values.auth.enableLoopbackUser }}\\n{{- else}}\\nloopback_users.guest = {{ .Values.auth.enableLoopbackUser }}\\n{{- end }}\\n{{ template \\\"rabbitmq.extraConfiguration\\\" . }}\\n{{- if .Values.auth.tls.enabled }}\\nssl_options.verify = {{ .Values.auth.tls.sslOptionsVerify }}\\nlisteners.ssl.default = {{ .Values.service.ports.amqpTls }}\\nssl_options.fail_if_no_peer_cert = {{ .Values.auth.tls.failIfNoPeerCert }}\\nssl_options.cacertfile = /opt/bitnami/rabbitmq/certs/ca_certificate.pem\\nssl_options.certfile = /opt/bitnami/rabbitmq/certs/server_certificate.pem\\nssl_options.keyfile = /opt/bitnami/rabbitmq/certs/server_key.pem\\n{{- if .Values.auth.tls.sslOptionsPassword.enabled }}\\nssl_options.password = {{ template \\\"rabbitmq.tlsSslOptionsPassword\\\" . }}\\n{{- end }}\\n{{- end }}\\n{{- if .Values.ldap.enabled }}\\nauth_backends.1.authn = ldap\\nauth_backends.1.authz = {{ ternary \\\"ldap\\\" \\\"internal\\\" .Values.ldap.authorisationEnabled }}\\nauth_backends.2 = internal\\n{{- $host :=  list }}\\n{{- $port :=  ternary 636 389 .Values.ldap.tls.enabled }}\\n{{- if .Values.ldap.uri }}\\n{{- $hostPort := get (urlParse .Values.ldap.uri) \\\"host\\\" }}\\n{{- $host = list (index (splitList \\\":\\\" $hostPort) 0) -}}\\n{{- if (contains \\\":\\\" $hostPort) }}\\n{{- $port = index (splitList \\\":\\\" $hostPort) 1 -}}\\n{{- end }}\\n{{- end }}\\n{{- range $index, $server := concat $host .Values.ldap.servers }}\\nauth_ldap.servers.{{ add $index 1 }} = {{ $server }}\\n{{- end }}\\nauth_ldap.port = {{ coalesce .Values.ldap.port $port }}\\n{{- if or .Values.ldap.user_dn_pattern .Values.ldap.userDnPattern }}\\nauth_ldap.user_dn_pattern = {{ coalesce .Values.ldap.user_dn_pattern .Values.ldap.userDnPattern }}\\n{{- end }}\\n{{- if .Values.ldap.basedn }}\\nauth_ldap.dn_lookup_base = {{ .Values.ldap.basedn }}\\n{{- end }}\\n{{- if .Values.ldap.uidField }}\\nauth_ldap.dn_lookup_attribute = {{ .Values.ldap.uidField }}\\n{{- end }}\\n{{- if .Values.ldap.binddn }}\\nauth_ldap.dn_lookup_bind.user_dn = {{ .Values.ldap.binddn }}\\nauth_ldap.dn_lookup_bind.password = {{ required \\\"'ldap.bindpw' is required when 'ldap.binddn' is defined\\\" .Values.ldap.bindpw }}\\n{{- end }}\\n{{- if .Values.ldap.tls.enabled }}\\nauth_ldap.use_ssl = {{ not .Values.ldap.tls.startTls }}\\nauth_ldap.use_starttls = {{ .Values.ldap.tls.startTls }}\\n{{- if .Values.ldap.tls.CAFilename }}\\nauth_ldap.ssl_options.cacertfile = {{ .Values.ldap.tls.certificatesMountPath }}/{{ .Values.ldap.tls.CAFilename }}\\n{{- end }}\\n{{- if .Values.ldap.tls.certFilename }}\\nauth_ldap.ssl_options.certfile = {{ .Values.ldap.tls.certificatesMountPath }}/{{ .Values.ldap.tls.certFilename }}\\nauth_ldap.ssl_options.keyfile = {{ .Values.ldap.tls.certificatesMountPath }}/{{ required \\\"'ldap.tls.certKeyFilename' is required when 'ldap.tls.certFilename' is defined\\\" .Values.ldap.tls.certKeyFilename }}\\n{{- end }}\\n{{- if .Values.ldap.tls.skipVerify }}\\nauth_ldap.ssl_options.verify = verify_none\\nauth_ldap.ssl_options.fail_if_no_peer_cert = false\\n{{- else if .Values.ldap.tls.verify }}\\nauth_ldap.ssl_options.verify = {{ .Values.ldap.tls.verify }}\\n{{- end }}\\n{{- end }}\\n{{- end }}\\n{{- if .Values.metrics.enabled }}\\n## Prometheus metrics\\n##\\nprometheus.tcp.port = {{ .Values.containerPorts.metrics }}\\n{{- end }}\\n{{- if .Values.memoryHighWatermark.enabled }}\\n## Memory Threshold\\n##\\ntotal_memory_available_override_value = {{ include \\\"rabbitmq.toBytes\\\" .Values.resources.limits.memory }}\\nvm_memory_high_watermark.{{ .Values.memoryHighWatermark.type }} = {{ .Values.memoryHighWatermark.value }}\\n## TCP Listen Options\\n##\\ntcp_listen_options.backlog = {{ .Values.tcpListenOptions.backlog }}\\ntcp_listen_options.nodelay = {{ .Values.tcpListenOptions.nodelay }}\\ntcp_listen_options.linger.on      = {{ .Values.tcpListenOptions.linger.lingerOn }}\\ntcp_listen_options.linger.timeout = {{ .Values.tcpListenOptions.linger.timeout }}\\ntcp_listen_options.keepalive = {{ .Values.tcpListenOptions.keepalive }}\\n{{- end }}\",\"configurationExistingSecret\":\"\",\"containerPorts\":{\"amqp\":5672,\"amqpTls\":5671,\"dist\":25672,\"epmd\":4369,\"manager\":15672,\"metrics\":9419},\"containerSecurityContext\":{\"enabled\":true,\"runAsNonRoot\":true,\"runAsUser\":1001},\"customLivenessProbe\":{},\"customReadinessProbe\":{},\"customStartupProbe\":{},\"diagnosticMode\":{\"args\":[\"infinity\"],\"command\":[\"sleep\"],\"enabled\":false},\"dnsConfig\":{},\"dnsPolicy\":\"\",\"extraConfiguration\":\"#default_vhost = {{ .Release.Namespace }}-vhost\\n#disk_free_limit.absolute = 50MB\",\"extraConfigurationExistingSecret\":\"\",\"extraContainerPorts\":[],\"extraDeploy\":[],\"extraEnvVars\":[],\"extraEnvVarsCM\":\"\",\"extraEnvVarsSecret\":\"\",\"extraPlugins\":\"rabbitmq_auth_backend_ldap\",\"extraSecrets\":{},\"extraSecretsPrependReleaseName\":false,\"extraVolumeMounts\":[],\"extraVolumes\":[],\"featureFlags\":\"\",\"fullnameOverride\":\"\",\"global\":{\"imagePullSecrets\":[],\"imageRegistry\":\"\",\"storageClass\":\"\"},\"hostAliases\":[],\"image\":{\"debug\":false,\"digest\":\"\",\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/rabbitmq\",\"tag\":\"3.11.11-debian-11-r0\"},\"ingress\":{\"annotations\":{},\"enabled\":false,\"existingSecret\":\"\",\"extraHosts\":[],\"extraPaths\":[],\"extraRules\":[],\"extraTls\":[],\"hostname\":\"rabbitmq.local\",\"ingressClassName\":\"\",\"path\":\"/\",\"pathType\":\"ImplementationSpecific\",\"secrets\":[],\"selfSigned\":false,\"tls\":false},\"initContainers\":[],\"initScripts\":{},\"initScriptsCM\":\"\",\"initScriptsSecret\":\"\",\"kubeVersion\":\"\",\"ldap\":{\"authorisationEnabled\":false,\"basedn\":\"\",\"binddn\":\"\",\"bindpw\":\"\",\"enabled\":false,\"port\":\"\",\"servers\":[],\"tls\":{\"CAFilename\":\"\",\"certFilename\":\"\",\"certKeyFilename\":\"\",\"certificatesMountPath\":\"/opt/bitnami/rabbitmq/ldap/certs\",\"certificatesSecret\":\"\",\"enabled\":false,\"skipVerify\":false,\"startTls\":false,\"verify\":\"verify_peer\"},\"uidField\":\"\",\"uri\":\"\",\"userDnPattern\":\"\"},\"lifecycleHooks\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":6,\"initialDelaySeconds\":120,\"periodSeconds\":30,\"successThreshold\":1,\"timeoutSeconds\":20},\"loadDefinition\":{\"enabled\":false,\"existingSecret\":\"\",\"file\":\"/app/load_definition.json\"},\"logs\":\"-\",\"maxAvailableSchedulers\":\"\",\"memoryHighWatermark\":{\"enabled\":false,\"type\":\"relative\",\"value\":0.4},\"metrics\":{\"enabled\":false,\"plugins\":\"rabbitmq_prometheus\",\"podAnnotations\":{\"prometheus.io/port\":\"{{ .Values.service.ports.metrics }}\",\"prometheus.io/scrape\":\"true\"},\"prometheusRule\":{\"additionalLabels\":{},\"enabled\":false,\"namespace\":\"\",\"rules\":[]},\"serviceMonitor\":{\"annotations\":{},\"enabled\":false,\"honorLabels\":false,\"interval\":\"30s\",\"jobLabel\":\"\",\"labels\":{},\"metricRelabelings\":[],\"namespace\":\"\",\"path\":\"\",\"podTargetLabels\":{},\"relabelings\":[],\"scrapeTimeout\":\"\",\"selector\":{},\"targetLabels\":{}}},\"nameOverride\":\"\",\"namespaceOverride\":\"\",\"networkPolicy\":{\"additionalRules\":[],\"allowExternal\":true,\"enabled\":false},\"nodeAffinityPreset\":{\"key\":\"\",\"type\":\"\",\"values\":[]},\"nodeSelector\":{},\"onlineSchedulers\":\"\",\"pdb\":{\"create\":false,\"maxUnavailable\":\"\",\"minAvailable\":1},\"persistence\":{\"accessModes\":[\"ReadWriteOnce\"],\"annotations\":{},\"enabled\":true,\"existingClaim\":\"\",\"labels\":{},\"mountPath\":\"/bitnami/rabbitmq/mnesia\",\"selector\":{},\"size\":\"8Gi\",\"storageClass\":\"\",\"subPath\":\"\"},\"plugins\":\"rabbitmq_management rabbitmq_peer_discovery_k8s\",\"podAffinityPreset\":\"\",\"podAnnotations\":{},\"podAntiAffinityPreset\":\"soft\",\"podLabels\":{},\"podManagementPolicy\":\"OrderedReady\",\"podSecurityContext\":{\"enabled\":true,\"fsGroup\":1001},\"priorityClassName\":\"\",\"rbac\":{\"create\":true},\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":30,\"successThreshold\":1,\"timeoutSeconds\":20},\"replicaCount\":1,\"resources\":{\"limits\":{},\"requests\":{}},\"schedulerName\":\"\",\"service\":{\"annotations\":{},\"annotationsHeadless\":{},\"clusterIP\":\"\",\"distPortEnabled\":true,\"epmdPortEnabled\":true,\"externalIPs\":[],\"externalTrafficPolicy\":\"Cluster\",\"extraPorts\":[],\"headless\":{\"annotations\":{}},\"labels\":{},\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"managerPortEnabled\":true,\"nodePorts\":{\"amqp\":\"\",\"amqpTls\":\"\",\"dist\":\"\",\"epmd\":\"\",\"manager\":\"\",\"metrics\":\"\"},\"portEnabled\":true,\"portNames\":{\"amqp\":\"amqp\",\"amqpTls\":\"amqp-ssl\",\"dist\":\"dist\",\"epmd\":\"epmd\",\"manager\":\"http-stats\",\"metrics\":\"metrics\"},\"ports\":{\"amqp\":5672,\"amqpTls\":5671,\"dist\":25672,\"epmd\":4369,\"manager\":15672,\"metrics\":9419},\"sessionAffinity\":\"None\",\"sessionAffinityConfig\":{},\"type\":\"ClusterIP\"},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":\"\"},\"serviceBindings\":{\"enabled\":false},\"servicenameOverride\":\"\",\"sidecars\":[],\"startupProbe\":{\"enabled\":false,\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":30,\"successThreshold\":1,\"timeoutSeconds\":20},\"statefulsetAnnotations\":{},\"statefulsetLabels\":{},\"tcpListenOptions\":{\"backlog\":128,\"keepalive\":false,\"linger\":{\"lingerOn\":true,\"timeout\":0},\"nodelay\":true},\"terminationGracePeriodSeconds\":120,\"tolerations\":[],\"topologySpreadConstraints\":[],\"ulimitNofiles\":\"65536\",\"updateStrategy\":{\"type\":\"RollingUpdate\"},\"volumePermissions\":{\"containerSecurityContext\":{\"runAsUser\":0},\"enabled\":false,\"image\":{\"digest\":\"\",\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/bitnami-shell\",\"tag\":\"11-debian-11-r98\"},\"resources\":{\"limits\":{},\"requests\":{}}}}",
                "version": "11.12.0"
              }
            ],
            "name": "my-rabbitmq-release",
            "namespace": "default",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://charts.bitnami.com/bitnami",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "## @section Global parameters\n## Global Docker image parameters\n## Please, note that this will override the image parameters, including dependencies, configured to use the global value\n## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass\n##\n\n## @param global.imageRegistry Global Docker image registry\n## @param global.imagePullSecrets Global Docker registry secret names as an array\n## @param global.storageClass Global StorageClass for Persistent Volume(s)\n##\nglobal:\n  imageRegistry: \"\"\n  ## E.g.\n  ## imagePullSecrets:\n  ##   - myRegistryKeySecretName\n  ##\n  imagePullSecrets: []\n  storageClass: \"\"\n\n## @section RabbitMQ Image parameters\n## Bitnami RabbitMQ image version\n## ref: https://hub.docker.com/r/bitnami/rabbitmq/tags/\n## @param image.registry RabbitMQ image registry\n## @param image.repository RabbitMQ image repository\n## @param image.tag RabbitMQ image tag (immutable tags are recommended)\n## @param image.digest RabbitMQ image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag\n## @param image.pullPolicy RabbitMQ image pull policy\n## @param image.pullSecrets Specify docker-registry secret names as an array\n## @param image.debug Set to true if you would like to see extra information on logs\n##\nimage:\n  registry: docker.io\n  repository: bitnami/rabbitmq\n  tag: 3.11.11-debian-11-r0\n  digest: \"\"\n  ## set to true if you would like to see extra information on logs\n  ## It turns BASH and/or NAMI debugging in the image\n  ##\n  debug: false\n  ## Specify a imagePullPolicy\n  ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n  ## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n  ##\n  pullPolicy: IfNotPresent\n  ## Optionally specify an array of imagePullSecrets.\n  ## Secrets must be manually created in the namespace.\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ## Example:\n  ## pullSecrets:\n  ##   - myRegistryKeySecretName\n  ##\n  pullSecrets: []\n\n## @section Common parameters\n##\n\n## @param nameOverride String to partially override rabbitmq.fullname template (will maintain the release name)\n##\nnameOverride: \"\"\n## @param fullnameOverride String to fully override rabbitmq.fullname template\n##\nfullnameOverride: \"\"\n## @param namespaceOverride String to fully override common.names.namespace\n##\nnamespaceOverride: \"\"\n## @param kubeVersion Force target Kubernetes version (using Helm capabilities if not set)\n##\nkubeVersion: \"\"\n## @param clusterDomain Kubernetes Cluster Domain\n##\nclusterDomain: cluster.local\n## @param extraDeploy Array of extra objects to deploy with the release\n##\nextraDeploy: []\n## @param commonAnnotations Annotations to add to all deployed objects\n##\ncommonAnnotations: {}\n## @param servicenameOverride String to partially override headless service name\n##\nservicenameOverride: \"\"\n## @param commonLabels Labels to add to all deployed objects\n##\ncommonLabels: {}\n\n## @param serviceBindings.enabled Create secret for service binding (Experimental)\n## Ref: https://servicebinding.io/service-provider/\n##\nserviceBindings:\n  enabled: false\n\n## Enable diagnostic mode in the deployment\n##\ndiagnosticMode:\n  ## @param diagnosticMode.enabled Enable diagnostic mode (all probes will be disabled and the command will be overridden)\n  ##\n  enabled: false\n  ## @param diagnosticMode.command Command to override all containers in the deployment\n  ##\n  command:\n    - sleep\n  ## @param diagnosticMode.args Args to override all containers in the deployment\n  ##\n  args:\n    - infinity\n\n## @param hostAliases Deployment pod host aliases\n## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/\n##\nhostAliases: []\n## @param dnsPolicy DNS Policy for pod\n## ref: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/\n## E.g.\n## dnsPolicy: ClusterFirst\n##\ndnsPolicy: \"\"\n## @param dnsConfig DNS Configuration pod\n## ref: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/\n## E.g.\n## dnsConfig:\n##   options:\n##   - name: ndots\n##     value: \"4\"\n##\ndnsConfig: {}\n## RabbitMQ Authentication parameters\n##\nauth:\n  ## @param auth.username RabbitMQ application username\n  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/rabbitmq#environment-variables\n  ##\n  username: user\n  ## @param auth.password RabbitMQ application password\n  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/rabbitmq#environment-variables\n  ##\n  password: \"\"\n  ## @param auth.securePassword Whether to set the RabbitMQ password securely. This is incompatible with loading external RabbitMQ definitions and 'true' when not setting the auth.password parameter.\n  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/rabbitmq#environment-variables\n  ##\n  securePassword: true\n  ## @param auth.existingPasswordSecret Existing secret with RabbitMQ credentials (must contain a value for `rabbitmq-password` key)\n  ## e.g:\n  ## existingPasswordSecret: name-of-existing-secret\n  ##\n  existingPasswordSecret: \"\"\n  ## @param auth.enableLoopbackUser Enable Loopback user access? Be advised, that enabling the loopback user is a possible security risk!\n  ##\n  enableLoopbackUser: false\n  ## @param auth.erlangCookie Erlang cookie to determine whether different nodes are allowed to communicate with each other\n  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/rabbitmq#environment-variables\n  ##\n  erlangCookie: \"\"\n  ## @param auth.existingErlangSecret Existing secret with RabbitMQ Erlang cookie (must contain a value for `rabbitmq-erlang-cookie` key)\n  ## e.g:\n  ## existingErlangSecret: name-of-existing-secret\n  ##\n  existingErlangSecret: \"\"\n\n  ## Enable encryption to rabbitmq\n  ## ref: https://www.rabbitmq.com/ssl.html\n  ## @param auth.tls.enabled Enable TLS support on RabbitMQ\n  ## @param auth.tls.autoGenerated Generate automatically self-signed TLS certificates\n  ## @param auth.tls.failIfNoPeerCert When set to true, TLS connection will be rejected if client fails to provide a certificate\n  ## @param auth.tls.sslOptionsVerify Should [peer verification](https://www.rabbitmq.com/ssl.html#peer-verification) be enabled?\n  ## @param auth.tls.sslOptionsPassword.enabled Enable usage of password for private Key\n  ## @param auth.tls.sslOptionsPassword.existingSecret Name of existing Secret containing the sslOptionsPassword\n  ## @param auth.tls.sslOptionsPassword.key Enable Key referring to sslOptionsPassword in Secret specified in auth.tls.sslOptionsPassword.existingSecret\n  ## @param auth.tls.sslOptionsPassword.password Use this string as Password. If set, auth.tls.sslOptionsPassword.existingSecret and auth.tls.sslOptionsPassword.key are ignored\n  ## @param auth.tls.caCertificate Certificate Authority (CA) bundle content\n  ## @param auth.tls.serverCertificate Server certificate content\n  ## @param auth.tls.serverKey Server private key content\n  ## @param auth.tls.existingSecret Existing secret with certificate content to RabbitMQ credentials\n  ## @param auth.tls.existingSecretFullChain Whether or not the existing secret contains the full chain in the certificate (`tls.crt`). Will be used in place of `ca.cert` if `true`.\n  ## @param auth.tls.overrideCaCertificate Existing secret with certificate content be mounted instead of the `ca.crt` coming from caCertificate or existingSecret/existingSecretFullChain.\n  ##\n  tls:\n    enabled: false\n    autoGenerated: false\n    failIfNoPeerCert: true\n    sslOptionsVerify: verify_peer\n    sslOptionsPassword:\n      enabled: false\n      existingSecret: \"\"\n      key: \"\"\n      password: \"\"\n    caCertificate: \"\"\n    serverCertificate: \"\"\n    serverKey: \"\"\n    existingSecret: \"\"\n    existingSecretFullChain: false\n    overrideCaCertificate: \"\"\n\n## @param logs Path of the RabbitMQ server's Erlang log file. Value for the `RABBITMQ_LOGS` environment variable\n## ref: https://www.rabbitmq.com/logging.html#log-file-location\n##\nlogs: \"-\"\n## @param ulimitNofiles RabbitMQ Max File Descriptors\n## ref: https://github.com/bitnami/containers/tree/main/bitnami/rabbitmq#environment-variables\n## ref: https://www.rabbitmq.com/install-debian.html#kernel-resource-limits\n##\nulimitNofiles: \"65536\"\n## RabbitMQ maximum available scheduler threads and online scheduler threads. By default it will create a thread per CPU detected, with the following parameters you can tune it manually.\n## ref: https://hamidreza-s.github.io/erlang/scheduling/real-time/preemptive/migration/2016/02/09/erlang-scheduler-details.html#scheduler-threads\n## ref: https://github.com/bitnami/charts/issues/2189\n## @param maxAvailableSchedulers RabbitMQ maximum available scheduler threads\n## @param onlineSchedulers RabbitMQ online scheduler threads\n##\nmaxAvailableSchedulers: \"\"\nonlineSchedulers: \"\"\n\n## The memory threshold under which RabbitMQ will stop reading from client network sockets, in order to avoid being killed by the OS\n## ref: https://www.rabbitmq.com/alarms.html\n## ref: https://www.rabbitmq.com/memory.html#threshold\n##\nmemoryHighWatermark:\n  ## @param memoryHighWatermark.enabled Enable configuring Memory high watermark on RabbitMQ\n  ##\n  enabled: false\n  ## @param memoryHighWatermark.type Memory high watermark type. Either `absolute` or `relative`\n  ##\n  type: \"relative\"\n  ## Memory high watermark value.\n  ## @param memoryHighWatermark.value Memory high watermark value\n  ## The default value of 0.4 stands for 40% of available RAM\n  ## Note: the memory relative limit is applied to the resource.limits.memory to calculate the memory threshold\n  ## You can also use an absolute value, e.g.: 256MB\n  ##\n  value: 0.4\n\n## @param plugins List of default plugins to enable (should only be altered to remove defaults; for additional plugins use `extraPlugins`)\n##\nplugins: \"rabbitmq_management rabbitmq_peer_discovery_k8s\"\n## @param communityPlugins List of Community plugins (URLs) to be downloaded during container initialization\n## Combine it with extraPlugins to also enable them.\n##\ncommunityPlugins: \"\"\n## @param extraPlugins Extra plugins to enable (single string containing a space-separated list)\n## Use this instead of `plugins` to add new plugins\n##\nextraPlugins: \"rabbitmq_auth_backend_ldap\"\n\n## Clustering settings\n##\nclustering:\n  ## @param clustering.enabled Enable RabbitMQ clustering\n  ##\n  enabled: true\n  ## @param clustering.addressType Switch clustering mode. Either `ip` or `hostname`\n  ##\n  addressType: hostname\n  ## @param clustering.rebalance Rebalance master for queues in cluster when new replica is created\n  ## ref: https://www.rabbitmq.com/rabbitmq-queues.8.html#rebalance\n  ##\n  rebalance: false\n  ## @param clustering.forceBoot Force boot of an unexpectedly shut down cluster (in an unexpected order).\n  ## forceBoot executes 'rabbitmqctl force_boot' to force boot cluster shut down unexpectedly in an unknown order\n  ## ref: https://www.rabbitmq.com/rabbitmqctl.8.html#force_boot\n  ##\n  forceBoot: false\n  ## @param clustering.partitionHandling Switch Partition Handling Strategy. Either `autoheal` or `pause-minority` or `pause-if-all-down` or `ignore`\n  ## ref: https://www.rabbitmq.com/partitions.html#automatic-handling\n  ##\n  partitionHandling: autoheal\n\n## Loading a RabbitMQ definitions file to configure RabbitMQ\n##\nloadDefinition:\n  ## @param loadDefinition.enabled Enable loading a RabbitMQ definitions file to configure RabbitMQ\n  ##\n  enabled: false\n  ## @param loadDefinition.file Name of the definitions file\n  ##\n  file: \"/app/load_definition.json\"\n  ## @param loadDefinition.existingSecret Existing secret with the load definitions file\n  ## Can be templated if needed, e.g:\n  ## existingSecret: \"{{ .Release.Name }}-load-definition\"\n  ##\n  existingSecret: \"\"\n\n## @param command Override default container command (useful when using custom images)\n##\ncommand: []\n## @param args Override default container args (useful when using custom images)\n##\nargs: []\n## @param lifecycleHooks Overwrite livecycle for the RabbitMQ container(s) to automate configuration before or after startup\n##\nlifecycleHooks: {}\n## @param terminationGracePeriodSeconds Default duration in seconds k8s waits for container to exit before sending kill signal.\n## Any time in excess of 10 seconds will be spent waiting for any synchronization necessary for cluster not to lose data.\n##\nterminationGracePeriodSeconds: 120\n## @param extraEnvVars Extra environment variables to add to RabbitMQ pods\n## E.g:\n## extraEnvVars:\n##   - name: FOO\n##     value: BAR\n##\nextraEnvVars: []\n## @param extraEnvVarsCM Name of existing ConfigMap containing extra environment variables\n##\nextraEnvVarsCM: \"\"\n## @param extraEnvVarsSecret Name of existing Secret containing extra environment variables (in case of sensitive data)\n##\nextraEnvVarsSecret: \"\"\n\n## Container Ports\n## @param containerPorts.amqp\n## @param containerPorts.amqpTls\n## @param containerPorts.dist\n## @param containerPorts.manager\n## @param containerPorts.epmd\n## @param containerPorts.metrics\n##\ncontainerPorts:\n  amqp: 5672\n  amqpTls: 5671\n  dist: 25672\n  manager: 15672\n  epmd: 4369\n  metrics: 9419\n\n## @param initScripts Dictionary of init scripts. Evaluated as a template.\n## Specify dictionary of scripts to be run at first boot\n## Alternatively, you can put your scripts under the files/docker-entrypoint-initdb.d directory\n## For example:\n## initScripts:\n##   my_init_script.sh: |\n##      #!/bin/sh\n##      echo \"Do something.\"\n##\ninitScripts: {}\n## @param initScriptsCM ConfigMap with the init scripts. Evaluated as a template.\n## Note: This will override initScripts\n##\ninitScriptsCM: \"\"\n## @param initScriptsSecret Secret containing `/docker-entrypoint-initdb.d` scripts to be executed at initialization time that contain sensitive data. Evaluated as a template.\n##\ninitScriptsSecret: \"\"\n## @param extraContainerPorts Extra ports to be included in container spec, primarily informational\n## E.g:\n## extraContainerPorts:\n## - name: new_port_name\n##   containerPort: 1234\n##\nextraContainerPorts: []\n## @param configuration [string] RabbitMQ Configuration file content: required cluster configuration\n## Do not override unless you know what you are doing.\n## To add more configuration, use `extraConfiguration` of `advancedConfiguration` instead\n##\n\n## RabbitMQ tcp_listen_options parameters\n## See : https://www.rabbitmq.com/networking.html for additional information\n##\ntcpListenOptions:\n  ## @param tcpListenOptions.backlog Maximum size of the unaccepted TCP connections queue\n  ##\n  backlog: 128\n  ## @param tcpListenOptions.nodelay When set to true, deactivates Nagle's algorithm. Default is true. Highly recommended for most users.\n  ##\n  nodelay: true\n  ## tcpListenOptions.linger\n  ##\n  linger:\n    ## @param tcpListenOptions.linger.lingerOn Enable Server socket lingering\n    ##\n    lingerOn: true\n    ## @param tcpListenOptions.linger.timeout Server Socket lingering timeout\n    ##\n    timeout: 0\n  ## @param tcpListenOptions.keepalive When set to true, enables TCP keepalives\n  ##\n  keepalive: false\n\nconfiguration: |-\n  ## Username and password\n  ##\n  default_user = {{ .Values.auth.username }}\n  {{- if and (not .Values.auth.securePassword) .Values.auth.password }}\n  default_pass = {{ .Values.auth.password }}\n  {{- end }}\n  {{- if .Values.clustering.enabled }}\n  ## Clustering\n  ##\n  cluster_formation.peer_discovery_backend  = rabbit_peer_discovery_k8s\n  cluster_formation.k8s.host = kubernetes.default\n  cluster_formation.node_cleanup.interval = 10\n  cluster_formation.node_cleanup.only_log_warning = true\n  cluster_partition_handling = {{ .Values.clustering.partitionHandling }}\n  {{- end }}\n  {{- if .Values.loadDefinition.enabled }}\n  load_definitions = {{ .Values.loadDefinition.file }}\n  {{- end }}\n  # queue master locator\n  queue_master_locator = min-masters\n  # enable loopback user\n  {{- if not (empty .Values.auth.username) }}\n  loopback_users.{{ .Values.auth.username }} = {{ .Values.auth.enableLoopbackUser }}\n  {{- else}}\n  loopback_users.guest = {{ .Values.auth.enableLoopbackUser }}\n  {{- end }}\n  {{ template \"rabbitmq.extraConfiguration\" . }}\n  {{- if .Values.auth.tls.enabled }}\n  ssl_options.verify = {{ .Values.auth.tls.sslOptionsVerify }}\n  listeners.ssl.default = {{ .Values.service.ports.amqpTls }}\n  ssl_options.fail_if_no_peer_cert = {{ .Values.auth.tls.failIfNoPeerCert }}\n  ssl_options.cacertfile = /opt/bitnami/rabbitmq/certs/ca_certificate.pem\n  ssl_options.certfile = /opt/bitnami/rabbitmq/certs/server_certificate.pem\n  ssl_options.keyfile = /opt/bitnami/rabbitmq/certs/server_key.pem\n  {{- if .Values.auth.tls.sslOptionsPassword.enabled }}\n  ssl_options.password = {{ template \"rabbitmq.tlsSslOptionsPassword\" . }}\n  {{- end }}\n  {{- end }}\n  {{- if .Values.ldap.enabled }}\n  auth_backends.1.authn = ldap\n  auth_backends.1.authz = {{ ternary \"ldap\" \"internal\" .Values.ldap.authorisationEnabled }}\n  auth_backends.2 = internal\n  {{- $host :=  list }}\n  {{- $port :=  ternary 636 389 .Values.ldap.tls.enabled }}\n  {{- if .Values.ldap.uri }}\n  {{- $hostPort := get (urlParse .Values.ldap.uri) \"host\" }}\n  {{- $host = list (index (splitList \":\" $hostPort) 0) -}}\n  {{- if (contains \":\" $hostPort) }}\n  {{- $port = index (splitList \":\" $hostPort) 1 -}}\n  {{- end }}\n  {{- end }}\n  {{- range $index, $server := concat $host .Values.ldap.servers }}\n  auth_ldap.servers.{{ add $index 1 }} = {{ $server }}\n  {{- end }}\n  auth_ldap.port = {{ coalesce .Values.ldap.port $port }}\n  {{- if or .Values.ldap.user_dn_pattern .Values.ldap.userDnPattern }}\n  auth_ldap.user_dn_pattern = {{ coalesce .Values.ldap.user_dn_pattern .Values.ldap.userDnPattern }}\n  {{- end }}\n  {{- if .Values.ldap.basedn }}\n  auth_ldap.dn_lookup_base = {{ .Values.ldap.basedn }}\n  {{- end }}\n  {{- if .Values.ldap.uidField }}\n  auth_ldap.dn_lookup_attribute = {{ .Values.ldap.uidField }}\n  {{- end }}\n  {{- if .Values.ldap.binddn }}\n  auth_ldap.dn_lookup_bind.user_dn = {{ .Values.ldap.binddn }}\n  auth_ldap.dn_lookup_bind.password = {{ required \"'ldap.bindpw' is required when 'ldap.binddn' is defined\" .Values.ldap.bindpw }}\n  {{- end }}\n  {{- if .Values.ldap.tls.enabled }}\n  auth_ldap.use_ssl = {{ not .Values.ldap.tls.startTls }}\n  auth_ldap.use_starttls = {{ .Values.ldap.tls.startTls }}\n  {{- if .Values.ldap.tls.CAFilename }}\n  auth_ldap.ssl_options.cacertfile = {{ .Values.ldap.tls.certificatesMountPath }}/{{ .Values.ldap.tls.CAFilename }}\n  {{- end }}\n  {{- if .Values.ldap.tls.certFilename }}\n  auth_ldap.ssl_options.certfile = {{ .Values.ldap.tls.certificatesMountPath }}/{{ .Values.ldap.tls.certFilename }}\n  auth_ldap.ssl_options.keyfile = {{ .Values.ldap.tls.certificatesMountPath }}/{{ required \"'ldap.tls.certKeyFilename' is required when 'ldap.tls.certFilename' is defined\" .Values.ldap.tls.certKeyFilename }}\n  {{- end }}\n  {{- if .Values.ldap.tls.skipVerify }}\n  auth_ldap.ssl_options.verify = verify_none\n  auth_ldap.ssl_options.fail_if_no_peer_cert = false\n  {{- else if .Values.ldap.tls.verify }}\n  auth_ldap.ssl_options.verify = {{ .Values.ldap.tls.verify }}\n  {{- end }}\n  {{- end }}\n  {{- end }}\n  {{- if .Values.metrics.enabled }}\n  ## Prometheus metrics\n  ##\n  prometheus.tcp.port = {{ .Values.containerPorts.metrics }}\n  {{- end }}\n  {{- if .Values.memoryHighWatermark.enabled }}\n  ## Memory Threshold\n  ##\n  total_memory_available_override_value = {{ include \"rabbitmq.toBytes\" .Values.resources.limits.memory }}\n  vm_memory_high_watermark.{{ .Values.memoryHighWatermark.type }} = {{ .Values.memoryHighWatermark.value }}\n  ## TCP Listen Options\n  ##\n  tcp_listen_options.backlog = {{ .Values.tcpListenOptions.backlog }}\n  tcp_listen_options.nodelay = {{ .Values.tcpListenOptions.nodelay }}\n  tcp_listen_options.linger.on      = {{ .Values.tcpListenOptions.linger.lingerOn }}\n  tcp_listen_options.linger.timeout = {{ .Values.tcpListenOptions.linger.timeout }}\n  tcp_listen_options.keepalive = {{ .Values.tcpListenOptions.keepalive }}\n  {{- end }}\n\n## @param configurationExistingSecret Existing secret with the configuration to use as rabbitmq.conf.\n## Must contain the key \"rabbitmq.conf\"\n## Takes precedence over `configuration`, so do not use both simultaneously\n## With providing an existingSecret, extraConfiguration and extraConfigurationExistingSecret do not take any effect\n##\nconfigurationExistingSecret: \"\"\n\n## @param extraConfiguration [string] Configuration file content: extra configuration to be appended to RabbitMQ configuration\n## Use this instead of `configuration` to add more configuration\n## Do not use simultaneously with `extraConfigurationExistingSecret`\n##\nextraConfiguration: |-\n  #default_vhost = {{ .Release.Namespace }}-vhost\n  #disk_free_limit.absolute = 50MB\n\n## @param extraConfigurationExistingSecret Existing secret with the extra configuration to append to `configuration`.\n## Must contain the key \"extraConfiguration\"\n## Takes precedence over `extraConfiguration`, so do not use both simultaneously\n##\nextraConfigurationExistingSecret: \"\"\n\n## @param advancedConfiguration Configuration file content: advanced configuration\n## Use this as additional configuration in classic config format (Erlang term configuration format)\n##\n## LDAP authorisation example:\n## advancedConfiguration: |-\n##   [{rabbitmq_auth_backend_ldap,[\n##      {tag_queries,           [{administrator, {constant, true}},\n##                               {management,    {constant, true}}]}\n##   ]}].\n##\n## If both, advancedConfiguration and advancedConfigurationExistingSecret are set, then advancedConfiguration\n## will be used instead of the secret.\n#\nadvancedConfiguration: |-\n\n## @param advancedConfigurationExistingSecret Existing secret with the advanced configuration file (must contain a key `advanced.config`).\n## Use this as additional configuration in classic config format (Erlang term configuration format) as in advancedConfiguration\n## Do not use in combination with advancedConfiguration, will be ignored\n##\nadvancedConfigurationExistingSecret: \"\"\n\n## This subsystem was introduced in RabbitMQ 3.8.0 to allow rolling upgrades of cluster members without shutting down the entire cluster.\n## Feature flags are a mechanism that controls what features are considered to be enabled or available on all cluster nodes. If a feature flag is enabled, so is its associated feature (or behavior). If not then all nodes in the cluster will disable the feature (behavior).\n## e.g, drop_unroutable_metric,empty_basic_get_metric,implicit_default_bindings,maintenance_mode_status,quorum_queue,virtual_host_metadata\n## @param featureFlags that controls what features are considered to be enabled or available on all cluster nodes.\n##\nfeatureFlags: \"\"\n\n## LDAP configuration\n##\nldap:\n  ## @param ldap.enabled Enable LDAP support\n  ##\n  enabled: false\n  ## @param ldap.uri LDAP connection string.\n  ##\n  uri: \"\"\n  ## @param ldap.servers List of LDAP servers hostnames. This is valid only if ldap.uri is not set\n  ##\n  servers: []\n  ## @param ldap.port LDAP servers port. This is valid only if ldap.uri is not set\n  ##\n  port: \"\"\n\n  ## DEPRECATED ldap.user_dn_pattern it will removed in a future, please use userDnPattern instead\n  ## Pattern used to translate the provided username into a value to be used for the LDAP bind\n  ## @param ldap.userDnPattern Pattern used to translate the provided username into a value to be used for the LDAP bind.\n  ## ref: https://www.rabbitmq.com/ldap.html#usernames-and-dns\n  ##\n  userDnPattern: \"\"\n  ## @param ldap.binddn DN of the account used to search in the LDAP server.\n  ##\n  binddn: \"\"\n  ## @param ldap.bindpw Password for binddn account.\n  ##\n  bindpw: \"\"\n  ## @param ldap.basedn Base DN path where binddn account will search for the users.\n  ##\n  basedn: \"\"\n  ## @param ldap.uidField Field used to match with the user name (uid, samAccountName, cn, etc). It matches with 'dn_lookup_attribute' in RabbitMQ configuration\n  ##ï¿½ï¿½ref: https://www.rabbitmq.com/ldap.html#usernames-and-dns\n  ##\n  ## @param ldap.uidField Field used to match with the user name (uid, samAccountName, cn, etc). It matches with 'dn_lookup_attribute' in RabbitMQ configuration\n  ##\n  uidField: \"\"\n  ## @param ldap.authorisationEnabled Enable LDAP authorisation. Please set 'advancedConfiguration' with tag, topic, resources and vhost mappings\n  ## ref: https://www.rabbitmq.com/ldap.html#authorisation\n  ##\n  authorisationEnabled: false\n  ## @param ldap.tls.enabled Enabled TLS configuration.\n  ## @param ldap.tls.startTls Use STARTTLS instead of LDAPS.\n  ## @param ldap.tls.skipVerify Skip any SSL verification (hostanames or certificates)\n  ## @param ldap.tls.verify Verify connection. Valid values are 'verify_peer' or 'verify_none'\n  ## @param ldap.tls.certificatesMountPath Where LDAP certifcates are mounted.\n  ## @param ldap.tls.certificatesSecret Secret with LDAP certificates.\n  ## @param ldap.tls.CAFilename  CA certificate filename. Should match with the CA entry key in the ldap.tls.certificatesSecret.\n  ## @param ldap.tls.certFilename Client certificate filename to authenticate against the LDAP server. Should match with certificate the entry key in the ldap.tls.certificatesSecret.\n  ## @param ldap.tls.certKeyFilename Client Key filename to authenticate against the LDAP server. Should match with certificate the entry key in the ldap.tls.certificatesSecret.\n  ##\n  tls:\n    enabled: false\n    startTls: false\n    skipVerify: false\n    verify: \"verify_peer\"\n    certificatesMountPath: /opt/bitnami/rabbitmq/ldap/certs\n    certificatesSecret: \"\"\n    CAFilename: \"\"\n    certFilename: \"\"\n    certKeyFilename: \"\"\n\n## @param extraVolumeMounts Optionally specify extra list of additional volumeMounts\n## Examples:\n## extraVolumeMounts:\n##   - name: extras\n##     mountPath: /usr/share/extras\n##     readOnly: true\n##\nextraVolumeMounts: []\n## @param extraVolumes Optionally specify extra list of additional volumes .\n## Example:\n## extraVolumes:\n##   - name: extras\n##     emptyDir: {}\n##\nextraVolumes: []\n## @param extraSecrets Optionally specify extra secrets to be created by the chart.\n## This can be useful when combined with load_definitions to automatically create the secret containing the definitions to be loaded.\n## Example:\n## extraSecrets:\n##   load-definition:\n##     load_definition.json: |\n##       {\n##         ...\n##       }\n##\nextraSecrets: {}\n## @param extraSecretsPrependReleaseName Set this flag to true if extraSecrets should be created with \u003crelease-name\u003e prepended.\n##\nextraSecretsPrependReleaseName: false\n\n## @section Statefulset parameters\n##\n\n## @param replicaCount Number of RabbitMQ replicas to deploy\n##\nreplicaCount: 1\n## @param schedulerName Use an alternate scheduler, e.g. \"stork\".\n## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n##\nschedulerName: \"\"\n## RabbitMQ should be initialized one by one when building cluster for the first time.\n## Therefore, the default value of podManagementPolicy is 'OrderedReady'\n## Once the RabbitMQ participates in the cluster, it waits for a response from another\n## RabbitMQ in the same cluster at reboot, except the last RabbitMQ of the same cluster.\n## If the cluster exits gracefully, you do not need to change the podManagementPolicy\n## because the first RabbitMQ of the statefulset always will be last of the cluster.\n## However if the last RabbitMQ of the cluster is not the first RabbitMQ due to a failure,\n## you must change podManagementPolicy to 'Parallel'.\n## ref : https://www.rabbitmq.com/clustering.html#restarting\n## @param podManagementPolicy Pod management policy\n##\npodManagementPolicy: OrderedReady\n## @param podLabels RabbitMQ Pod labels. Evaluated as a template\n## Ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/\n##\npodLabels: {}\n## @param podAnnotations RabbitMQ Pod annotations. Evaluated as a template\n## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n##\npodAnnotations: {}\n## @param updateStrategy.type Update strategy type for RabbitMQ statefulset\n## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies\n##\nupdateStrategy:\n  ## StrategyType\n  ## Can be set to RollingUpdate or OnDelete\n  ##\n  type: RollingUpdate\n## @param statefulsetLabels RabbitMQ statefulset labels. Evaluated as a template\n## Ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/\n##\nstatefulsetLabels: {}\n## @param statefulsetAnnotations RabbitMQ statefulset annotations. Evaluated as a template\n## Ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n##\nstatefulsetAnnotations: {}\n## @param priorityClassName Name of the priority class to be used by RabbitMQ pods, priority class needs to be created beforehand\n## Ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/\n##\npriorityClassName: \"\"\n## @param podAffinityPreset Pod affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n##\npodAffinityPreset: \"\"\n## @param podAntiAffinityPreset Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n##\npodAntiAffinityPreset: soft\n\n## Node affinity preset\n## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity\n##\nnodeAffinityPreset:\n  ## @param nodeAffinityPreset.type Node affinity preset type. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n  ##\n  type: \"\"\n  ## @param nodeAffinityPreset.key Node label key to match Ignored if `affinity` is set.\n  ## E.g.\n  ## key: \"kubernetes.io/e2e-az-name\"\n  ##\n  key: \"\"\n  ## @param nodeAffinityPreset.values Node label values to match. Ignored if `affinity` is set.\n  ## E.g.\n  ## values:\n  ##   - e2e-az1\n  ##   - e2e-az2\n  ##\n  values: []\n\n## @param affinity Affinity for pod assignment. Evaluated as a template\n## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n## Note: podAffinityPreset, podAntiAffinityPreset, and  nodeAffinityPreset will be ignored when it's set\n##\naffinity: {}\n## @param nodeSelector Node labels for pod assignment. Evaluated as a template\n## ref: https://kubernetes.io/docs/user-guide/node-selection/\n##\nnodeSelector: {}\n## @param tolerations Tolerations for pod assignment. Evaluated as a template\n## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n##\ntolerations: []\n## @param topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains. Evaluated as a template\n## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods\n##\ntopologySpreadConstraints: []\n\n## RabbitMQ pods' Security Context\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod\n## @param podSecurityContext.enabled Enable RabbitMQ pods' Security Context\n## @param podSecurityContext.fsGroup Set RabbitMQ pod's Security Context fsGroup\n##\npodSecurityContext:\n  enabled: true\n  fsGroup: 1001\n\n## @param containerSecurityContext.enabled Enabled RabbitMQ containers' Security Context\n## @param containerSecurityContext.runAsUser Set RabbitMQ containers' Security Context runAsUser\n## @param containerSecurityContext.runAsNonRoot Set RabbitMQ container's Security Context runAsNonRoot\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n## Example:\n##   containerSecurityContext:\n##     capabilities:\n##       drop: [\"NET_RAW\"]\n##     readOnlyRootFilesystem: true\n##\ncontainerSecurityContext:\n  enabled: true\n  runAsUser: 1001\n  runAsNonRoot: true\n\n## RabbitMQ containers' resource requests and limits\n## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n## We usually recommend not to specify default resources and to leave this as a conscious\n## choice for the user. This also increases chances charts run on environments with little\n## resources, such as Minikube. If you do want to specify resources, uncomment the following\n## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n## @param resources.limits The resources limits for RabbitMQ containers\n## @param resources.requests The requested resources for RabbitMQ containers\n##\nresources:\n  ## Example:\n  ## limits:\n  ##    cpu: 1000m\n  ##    memory: 2Gi\n  ##\n  limits: {}\n  ## Examples:\n  ## requests:\n  ##    cpu: 1000m\n  ##    memory: 2Gi\n  ##\n  requests: {}\n\n## Configure RabbitMQ containers' extra options for liveness probe\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n## @param livenessProbe.enabled Enable livenessProbe\n## @param livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe\n## @param livenessProbe.periodSeconds Period seconds for livenessProbe\n## @param livenessProbe.timeoutSeconds Timeout seconds for livenessProbe\n## @param livenessProbe.failureThreshold Failure threshold for livenessProbe\n## @param livenessProbe.successThreshold Success threshold for livenessProbe\n##\nlivenessProbe:\n  enabled: true\n  initialDelaySeconds: 120\n  timeoutSeconds: 20\n  periodSeconds: 30\n  failureThreshold: 6\n  successThreshold: 1\n## Configure RabbitMQ containers' extra options for readiness probe\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n## @param readinessProbe.enabled Enable readinessProbe\n## @param readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe\n## @param readinessProbe.periodSeconds Period seconds for readinessProbe\n## @param readinessProbe.timeoutSeconds Timeout seconds for readinessProbe\n## @param readinessProbe.failureThreshold Failure threshold for readinessProbe\n## @param readinessProbe.successThreshold Success threshold for readinessProbe\n##\nreadinessProbe:\n  enabled: true\n  initialDelaySeconds: 10\n  timeoutSeconds: 20\n  periodSeconds: 30\n  failureThreshold: 3\n  successThreshold: 1\n\n## Configure RabbitMQ containers' extra options for startup probe\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n## @param startupProbe.enabled Enable startupProbe\n## @param startupProbe.initialDelaySeconds Initial delay seconds for startupProbe\n## @param startupProbe.periodSeconds Period seconds for startupProbe\n## @param startupProbe.timeoutSeconds Timeout seconds for startupProbe\n## @param startupProbe.failureThreshold Failure threshold for startupProbe\n## @param startupProbe.successThreshold Success threshold for startupProbe\n##\nstartupProbe:\n  enabled: false\n  initialDelaySeconds: 10\n  timeoutSeconds: 20\n  periodSeconds: 30\n  failureThreshold: 3\n  successThreshold: 1\n\n## @param customLivenessProbe Override default liveness probe\n##\ncustomLivenessProbe: {}\n## @param customReadinessProbe Override default readiness probe\n##\ncustomReadinessProbe: {}\n## @param customStartupProbe Define a custom startup probe\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-startup-probes\n##\ncustomStartupProbe: {}\n## @param initContainers Add init containers to the RabbitMQ pod\n## Example:\n## initContainers:\n##   - name: your-image-name\n##     image: your-image\n##     imagePullPolicy: Always\n##     ports:\n##       - name: portname\n##         containerPort: 1234\n##\ninitContainers: []\n## @param sidecars Add sidecar containers to the RabbitMQ pod\n## Example:\n## sidecars:\n##   - name: your-image-name\n##     image: your-image\n##     imagePullPolicy: Always\n##     ports:\n##       - name: portname\n##         containerPort: 1234\n##\nsidecars: []\n\n## Pod Disruption Budget configuration\n## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n##\npdb:\n  ## @param pdb.create Enable/disable a Pod Disruption Budget creation\n  ##\n  create: false\n  ## @param pdb.minAvailable Minimum number/percentage of pods that should remain scheduled\n  ##\n  minAvailable: 1\n  ## @param pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable\n  ##\n  maxUnavailable: \"\"\n\n## @section RBAC parameters\n##\n\n## RabbitMQ pods ServiceAccount\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n##\nserviceAccount:\n  ## @param serviceAccount.create Enable creation of ServiceAccount for RabbitMQ pods\n  ##\n  create: true\n  ## @param serviceAccount.name Name of the created serviceAccount\n  ## If not set and create is true, a name is generated using the rabbitmq.fullname template\n  ##\n  name: \"\"\n  ## @param serviceAccount.automountServiceAccountToken Auto-mount the service account token in the pod\n  ##\n  automountServiceAccountToken: true\n  ## @param serviceAccount.annotations Annotations for service account. Evaluated as a template. Only used if `create` is `true`.\n  ##\n  annotations: {}\n\n## Role Based Access\n## ref: https://kubernetes.io/docs/admin/authorization/rbac/\n##\nrbac:\n  ## @param rbac.create Whether RBAC rules should be created\n  ## binding RabbitMQ ServiceAccount to a role\n  ## that allows RabbitMQ pods querying the K8s API\n  ##\n  create: true\n\n## @section Persistence parameters\n##\n\npersistence:\n  ## @param persistence.enabled Enable RabbitMQ data persistence using PVC\n  ##\n  enabled: true\n  ## @param persistence.storageClass PVC Storage Class for RabbitMQ data volume\n  ## If defined, storageClassName: \u003cstorageClass\u003e\n  ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n  ## If undefined (the default) or set to null, no storageClassName spec is\n  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n  ##   GKE, AWS \u0026 OpenStack)\n  ##\n  storageClass: \"\"\n  ## @param persistence.selector Selector to match an existing Persistent Volume\n  ## selector:\n  ##   matchLabels:\n  ##     app: my-app\n  ##\n  selector: {}\n  ## @param persistence.accessModes PVC Access Modes for RabbitMQ data volume\n  ##\n  accessModes:\n    - ReadWriteOnce\n  ## @param persistence.existingClaim Provide an existing PersistentVolumeClaims\n  ## The value is evaluated as a template\n  ## So, for example, the name can depend on .Release or .Chart\n  ##\n  existingClaim: \"\"\n  ## @param persistence.mountPath The path the volume will be mounted at\n  ## Note: useful when using custom RabbitMQ images\n  ##\n  mountPath: /bitnami/rabbitmq/mnesia\n  ## @param persistence.subPath The subdirectory of the volume to mount to\n  ## Useful in dev environments and one PV for multiple services\n  ##\n  subPath: \"\"\n  ## @param persistence.size PVC Storage Request for RabbitMQ data volume\n  ## If you change this value, you might have to adjust `rabbitmq.diskFreeLimit` as well\n  ##\n  size: 8Gi\n  ## @param persistence.annotations Persistence annotations. Evaluated as a template\n  ## Example:\n  ## annotations:\n  ##   example.io/disk-volume-type: SSD\n  ##\n  annotations: {}\n  ## @param persistence.labels Persistence labels. Evaluated as a template\n  ## Example:\n  ## labels:\n  ##   app: my-app\n  labels: {}\n\n## @section Exposure parameters\n##\n\n## Kubernetes service type\n##\nservice:\n  ## @param service.type Kubernetes Service type\n  ##\n  type: ClusterIP\n\n  ## @param service.portEnabled Amqp port. Cannot be disabled when `auth.tls.enabled` is `false`. Listener can be disabled with `listeners.tcp = none`.\n  ##\n  portEnabled: true\n  ## @param service.distPortEnabled Erlang distribution server port\n  ##\n  distPortEnabled: true\n  ## @param service.managerPortEnabled RabbitMQ Manager port\n  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/rabbitmq#environment-variables\n  ##\n  managerPortEnabled: true\n  ## @param service.epmdPortEnabled RabbitMQ EPMD Discovery service port\n  ##\n  epmdPortEnabled: true\n  ## Service ports\n  ## @param service.ports.amqp Amqp service port\n  ## @param service.ports.amqpTls Amqp TLS service port\n  ## @param service.ports.dist Erlang distribution service port\n  ## @param service.ports.manager RabbitMQ Manager service port\n  ## @param service.ports.metrics RabbitMQ Prometheues metrics service port\n  ## @param service.ports.epmd EPMD Discovery service port\n  ##\n  ports:\n    amqp: 5672\n    amqpTls: 5671\n    dist: 25672\n    manager: 15672\n    metrics: 9419\n    epmd: 4369\n  ## Service ports name\n  ## @param service.portNames.amqp Amqp service port name\n  ## @param service.portNames.amqpTls Amqp TLS service port name\n  ## @param service.portNames.dist Erlang distribution service port name\n  ## @param service.portNames.manager RabbitMQ Manager service port name\n  ## @param service.portNames.metrics RabbitMQ Prometheues metrics service port name\n  ## @param service.portNames.epmd EPMD Discovery service port name\n  ##\n  portNames:\n    amqp: \"amqp\"\n    amqpTls: \"amqp-ssl\"\n    dist: \"dist\"\n    manager: \"http-stats\"\n    metrics: \"metrics\"\n    epmd: \"epmd\"\n\n  ## Node ports to expose\n  ## @param service.nodePorts.amqp Node port for Ampq\n  ## @param service.nodePorts.amqpTls Node port for Ampq TLS\n  ## @param service.nodePorts.dist Node port for Erlang distribution\n  ## @param service.nodePorts.manager Node port for RabbitMQ Manager\n  ## @param service.nodePorts.epmd Node port for EPMD Discovery\n  ## @param service.nodePorts.metrics Node port for RabbitMQ Prometheues metrics\n  ##\n  nodePorts:\n    amqp: \"\"\n    amqpTls: \"\"\n    dist: \"\"\n    manager: \"\"\n    epmd: \"\"\n    metrics: \"\"\n  ## @param service.extraPorts Extra ports to expose in the service\n  ## E.g.:\n  ## extraPorts:\n  ## - name: new_svc_name\n  ##   port: 1234\n  ##   targetPort: 1234\n  ##\n  extraPorts: []\n  ## @param service.loadBalancerSourceRanges Address(es) that are allowed when service is `LoadBalancer`\n  ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service\n  ## e.g:\n  ## loadBalancerSourceRanges:\n  ## - 10.10.10.0/24\n  ##\n  loadBalancerSourceRanges: []\n  ## @param service.externalIPs Set the ExternalIPs\n  ##\n  externalIPs: []\n  ## @param service.externalTrafficPolicy Enable client source IP preservation\n  ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip\n  ##\n  externalTrafficPolicy: Cluster\n  ## @param service.loadBalancerIP Set the LoadBalancerIP\n  ##\n  loadBalancerIP: \"\"\n  ## @param service.clusterIP Kubernetes service Cluster IP\n  ## e.g.:\n  ## clusterIP: None\n  ##\n  clusterIP: \"\"\n  ## @param service.labels Service labels. Evaluated as a template\n  ##\n  labels: {}\n  ## @param service.annotations Service annotations. Evaluated as a template\n  ## Example:\n  ## annotations:\n  ##   service.beta.kubernetes.io/aws-load-balancer-internal: 0.0.0.0/0\n  ##\n  annotations: {}\n  ## DEPRECATED service.annotationsHeadless it will removed in a future release, please use service.headless.annotations instead\n  ## @param service.annotationsHeadless Headless Service annotations. Evaluated as a template\n  ## Example:\n  ## annotations:\n  ##   external-dns.alpha.kubernetes.io/internal-hostname: rabbitmq.example.com\n  ##\n  annotationsHeadless: {}\n  ## Headless service properties\n  ##\n  headless:\n    ## @param service.headless.annotations Annotations for the headless service.\n    ##\n    annotations: {}\n  ## @param service.sessionAffinity Session Affinity for Kubernetes service, can be \"None\" or \"ClientIP\"\n  ## If \"ClientIP\", consecutive client requests will be directed to the same Pod\n  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies\n  ##\n  sessionAffinity: None\n  ## @param service.sessionAffinityConfig Additional settings for the sessionAffinity\n  ## sessionAffinityConfig:\n  ##   clientIP:\n  ##     timeoutSeconds: 300\n  ##\n  sessionAffinityConfig: {}\n\n## Configure the ingress resource that allows you to access the\n## RabbitMQ installation. Set up the URL\n## ref: https://kubernetes.io/docs/user-guide/ingress/\n##\ningress:\n  ## @param ingress.enabled Enable ingress resource for Management console\n  ##\n  enabled: false\n\n  ## @param ingress.path Path for the default host. You may need to set this to '/*' in order to use this with ALB ingress controllers.\n  ##\n  path: /\n\n  ## @param ingress.pathType Ingress path type\n  ##\n  pathType: ImplementationSpecific\n  ## @param ingress.hostname Default host for the ingress resource\n  ##\n  hostname: rabbitmq.local\n  ## @param ingress.annotations Additional annotations for the Ingress resource. To enable certificate autogeneration, place here your cert-manager annotations.\n  ## For a full list of possible ingress annotations, please see\n  ## ref: https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md\n  ## Use this parameter to set the required annotations for cert-manager, see\n  ## ref: https://cert-manager.io/docs/usage/ingress/#supported-annotations\n  ##\n  ## e.g:\n  ## annotations:\n  ##   kubernetes.io/ingress.class: nginx\n  ##   cert-manager.io/cluster-issuer: cluster-issuer-name\n  ##\n  annotations: {}\n  ## @param ingress.tls Enable TLS configuration for the hostname defined at `ingress.hostname` parameter\n  ## TLS certificates will be retrieved from a TLS secret with name: {{- printf \"%s-tls\" .Values.ingress.hostname }}\n  ## You can:\n  ##   - Use the `ingress.secrets` parameter to create this TLS secret\n  ##   - Rely on cert-manager to create it by setting the corresponding annotations\n  ##   - Rely on Helm to create self-signed certificates by setting `ingress.selfSigned=true`\n  ##\n  tls: false\n  ## @param ingress.selfSigned Set this to true in order to create a TLS secret for this ingress record\n  ## using self-signed certificates generated by Helm\n  ##\n  selfSigned: false\n  ## @param ingress.extraHosts The list of additional hostnames to be covered with this ingress record.\n  ## Most likely the hostname above will be enough, but in the event more hosts are needed, this is an array\n  ## e.g:\n  ## extraHosts:\n  ##   - name: rabbitmq.local\n  ##     path: /\n  ##\n  extraHosts: []\n  ## @param ingress.extraPaths An array with additional arbitrary paths that may need to be added to the ingress under the main host\n  ## e.g:\n  ## extraPaths:\n  ## - path: /*\n  ##   backend:\n  ##     serviceName: ssl-redirect\n  ##     servicePort: use-annotation\n  ##\n  extraPaths: []\n  ## @param ingress.extraRules The list of additional rules to be added to this ingress record. Evaluated as a template\n  ## Useful when looking for additional customization, such as using different backend\n  ##\n  extraRules: []\n  ## @param ingress.extraTls The tls configuration for additional hostnames to be covered with this ingress record.\n  ## see: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls\n  ## e.g:\n  ## extraTls:\n  ##   - hosts:\n  ##       - rabbitmq.local\n  ##     secretName: rabbitmq.local-tls\n  ##\n  extraTls: []\n  ## @param ingress.secrets Custom TLS certificates as secrets\n  ## NOTE: 'key' and 'certificate' are expected in PEM format\n  ## NOTE: 'name' should line up with a 'secretName' set further up\n  ## If it is not set and you're using cert-manager, this is unneeded, as it will create a secret for you with valid certificates\n  ## If it is not set and you're NOT using cert-manager either, self-signed certificates will be created valid for 365 days\n  ## It is also possible to create and manage the certificates outside of this helm chart\n  ## Please see README.md for more information\n  ## e.g:\n  ## secrets:\n  ##   - name: rabbitmq.local-tls\n  ##     key: |-\n  ##       -----BEGIN RSA PRIVATE KEY-----\n  ##       ...\n  ##       -----END RSA PRIVATE KEY-----\n  ##     certificate: |-\n  ##       -----BEGIN CERTIFICATE-----\n  ##       ...\n  ##       -----END CERTIFICATE-----\n  ##\n  secrets: []\n  ## @param ingress.ingressClassName IngressClass that will be be used to implement the Ingress (Kubernetes 1.18+)\n  ## This is supported in Kubernetes 1.18+ and required if you have more than one IngressClass marked as the default for your cluster .\n  ## ref: https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/\n  ##\n  ingressClassName: \"\"\n  ## @param ingress.existingSecret It is you own the certificate as secret.\n  ##\n  existingSecret: \"\"\n\n## Network Policy configuration\n## ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/\n##\nnetworkPolicy:\n  ## @param networkPolicy.enabled Enable creation of NetworkPolicy resources\n  ##\n  enabled: false\n  ## @param networkPolicy.allowExternal Don't require client label for connections\n  ## The Policy model to apply. When set to false, only pods with the correct\n  ## client label will have network access to the ports RabbitMQ is listening\n  ## on. When true, RabbitMQ will accept connections from any source\n  ## (with the correct destination port).\n  ##\n  allowExternal: true\n  ## @param networkPolicy.additionalRules Additional NetworkPolicy Ingress \"from\" rules to set. Note that all rules are OR-ed.\n  ## e.g:\n  ## additionalRules:\n  ##  - matchLabels:\n  ##    - role: frontend\n  ##  - matchExpressions:\n  ##    - key: role\n  ##      operator: In\n  ##      values:\n  ##        - frontend\n  ##\n  additionalRules: []\n\n## @section Metrics Parameters\n##\n\n## Prometheus Metrics\n##\nmetrics:\n  ## @param metrics.enabled Enable exposing RabbitMQ metrics to be gathered by Prometheus\n  ##\n  enabled: false\n  ## @param metrics.plugins Plugins to enable Prometheus metrics in RabbitMQ\n  ##\n  plugins: \"rabbitmq_prometheus\"\n  ## Prometheus pod annotations\n  ## @param metrics.podAnnotations [object] Annotations for enabling prometheus to access the metrics endpoint\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n  ##\n  podAnnotations:\n    prometheus.io/scrape: \"true\"\n    prometheus.io/port: \"{{ .Values.service.ports.metrics }}\"\n  ## Prometheus Service Monitor\n  ## ref: https://github.com/coreos/prometheus-operator\n  ##\n  serviceMonitor:\n    ## @param metrics.serviceMonitor.enabled Create ServiceMonitor Resource for scraping metrics using PrometheusOperator\n    ##\n    enabled: false\n    ## @param metrics.serviceMonitor.namespace Specify the namespace in which the serviceMonitor resource will be created\n    ##\n    namespace: \"\"\n    ## @param metrics.serviceMonitor.interval Specify the interval at which metrics should be scraped\n    ##\n    interval: 30s\n    ## @param metrics.serviceMonitor.scrapeTimeout Specify the timeout after which the scrape is ended\n    ## e.g:\n    ## scrapeTimeout: 30s\n    ##\n    scrapeTimeout: \"\"\n    ## @param metrics.serviceMonitor.jobLabel The name of the label on the target service to use as the job name in prometheus.\n    ##\n    jobLabel: \"\"\n    ## @param metrics.serviceMonitor.relabelings RelabelConfigs to apply to samples before scraping.\n    ##\n    relabelings: []\n    ## @param metrics.serviceMonitor.metricRelabelings MetricsRelabelConfigs to apply to samples before ingestion.\n    ##\n    metricRelabelings: []\n    ## @param metrics.serviceMonitor.honorLabels honorLabels chooses the metric's labels on collisions with target labels\n    ##\n    honorLabels: false\n    ## @param metrics.serviceMonitor.targetLabels Used to keep given service's labels in target\n    ## e.g:\n    ## - app.kubernetes.io/name\n    ##\n    targetLabels: {}\n    ## @param metrics.serviceMonitor.podTargetLabels Used to keep given pod's labels in target\n    ## e.g:\n    ## - app.kubernetes.io/name\n    ##\n    podTargetLabels: {}\n    ## @param metrics.serviceMonitor.path Define the path used by ServiceMonitor to scrap metrics\n    ## Could be /metrics for aggregated metrics or /metrics/per-object for more details\n    ##\n    path: \"\"\n    ## @param metrics.serviceMonitor.selector ServiceMonitor selector labels\n    ## ref: https://github.com/bitnami/charts/tree/main/bitnami/prometheus-operator#prometheus-configuration\n    ##\n    ## selector:\n    ##   prometheus: my-prometheus\n    ##\n    selector: {}\n    ## @param metrics.serviceMonitor.labels Extra labels for the ServiceMonitor\n    ##\n    labels: {}\n    ## @param metrics.serviceMonitor.annotations Extra annotations for the ServiceMonitor\n    ##\n    annotations: {}\n\n  ## Custom PrometheusRule to be defined\n  ## The value is evaluated as a template, so, for example, the value can depend on .Release or .Chart\n  ## ref: https://github.com/coreos/prometheus-operator#customresourcedefinitions\n  ##\n  prometheusRule:\n    ## @param metrics.prometheusRule.enabled Set this to true to create prometheusRules for Prometheus operator\n    ##\n    enabled: false\n    ## @param metrics.prometheusRule.additionalLabels Additional labels that can be used so prometheusRules will be discovered by Prometheus\n    ##\n    additionalLabels: {}\n    ## @param metrics.prometheusRule.namespace namespace where prometheusRules resource should be created\n    ##\n    namespace: \"\"\n    ## List of rules, used as template by Helm.\n    ## @param metrics.prometheusRule.rules List of rules, used as template by Helm.\n    ## These are just examples rules inspired from https://awesome-prometheus-alerts.grep.to/rules.html\n    ## rules:\n    ##   - alert: RabbitmqDown\n    ##     expr: rabbitmq_up{service=\"{{ template \"common.names.fullname\" . }}\"} == 0\n    ##     for: 5m\n    ##     labels:\n    ##       severity: error\n    ##     annotations:\n    ##       summary: Rabbitmq down (instance {{ \"{{ $labels.instance }}\" }})\n    ##       description: RabbitMQ node down\n    ##   - alert: ClusterDown\n    ##     expr: |\n    ##       sum(rabbitmq_running{service=\"{{ template \"common.names.fullname\" . }}\"})\n    ##       \u003c {{ .Values.replicaCount }}\n    ##     for: 5m\n    ##     labels:\n    ##       severity: error\n    ##     annotations:\n    ##       summary: Cluster down (instance {{ \"{{ $labels.instance }}\" }})\n    ##       description: |\n    ##           Less than {{ .Values.replicaCount }} nodes running in RabbitMQ cluster\n    ##           VALUE = {{ \"{{ $value }}\" }}\n    ##   - alert: ClusterPartition\n    ##     expr: rabbitmq_partitions{service=\"{{ template \"common.names.fullname\" . }}\"} \u003e 0\n    ##     for: 5m\n    ##     labels:\n    ##       severity: error\n    ##     annotations:\n    ##       summary: Cluster partition (instance {{ \"{{ $labels.instance }}\" }})\n    ##       description: |\n    ##           Cluster partition\n    ##           VALUE = {{ \"{{ $value }}\" }}\n    ##   - alert: OutOfMemory\n    ##     expr: |\n    ##       rabbitmq_node_mem_used{service=\"{{ template \"common.names.fullname\" . }}\"}\n    ##       / rabbitmq_node_mem_limit{service=\"{{ template \"common.names.fullname\" . }}\"}\n    ##       * 100 \u003e 90\n    ##     for: 5m\n    ##     labels:\n    ##       severity: warning\n    ##     annotations:\n    ##       summary: Out of memory (instance {{ \"{{ $labels.instance }}\" }})\n    ##       description: |\n    ##           Memory available for RabbmitMQ is low (\u003c 10%)\\n  VALUE = {{ \"{{ $value }}\" }}\n    ##           LABELS: {{ \"{{ $labels }}\" }}\n    ##   - alert: TooManyConnections\n    ##     expr: rabbitmq_connectionsTotal{service=\"{{ template \"common.names.fullname\" . }}\"} \u003e 1000\n    ##     for: 5m\n    ##     labels:\n    ##       severity: warning\n    ##     annotations:\n    ##       summary: Too many connections (instance {{ \"{{ $labels.instance }}\" }})\n    ##       description: |\n    ##           RabbitMQ instance has too many connections (\u003e 1000)\n    ##           VALUE = {{ \"{{ $value }}\" }}\\n  LABELS: {{ \"{{ $labels }}\" }}\n    ##\n    rules: []\n\n## @section Init Container Parameters\n##\n\n## Init Container parameters\n## Change the owner and group of the persistent volume(s) mountpoint(s) to 'runAsUser:fsGroup' on each component\n## values from the securityContext section of the component\n##\nvolumePermissions:\n  ## @param volumePermissions.enabled Enable init container that changes the owner and group of the persistent volume(s) mountpoint to `runAsUser:fsGroup`\n  ##\n  enabled: false\n  ## @param volumePermissions.image.registry Init container volume-permissions image registry\n  ## @param volumePermissions.image.repository Init container volume-permissions image repository\n  ## @param volumePermissions.image.tag Init container volume-permissions image tag\n  ## @param volumePermissions.image.digest Init container volume-permissions image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag\n  ## @param volumePermissions.image.pullPolicy Init container volume-permissions image pull policy\n  ## @param volumePermissions.image.pullSecrets Specify docker-registry secret names as an array\n  ##\n  image:\n    registry: docker.io\n    repository: bitnami/bitnami-shell\n    tag: 11-debian-11-r98\n    digest: \"\"\n    ## Specify a imagePullPolicy\n    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n    ## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n    ##\n    pullPolicy: IfNotPresent\n    ## Optionally specify an array of imagePullSecrets (secrets must be manually created in the namespace)\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n    ## Example:\n    ## pullSecrets:\n    ##   - myRegistryKeySecretName\n    ##\n    pullSecrets: []\n  ## Init Container resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## We usually recommend not to specify default resources and to leave this as a conscious\n  ## choice for the user. This also increases chances charts run on environments with little\n  ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n  ## @param volumePermissions.resources.limits Init container volume-permissions resource limits\n  ## @param volumePermissions.resources.requests Init container volume-permissions resource requests\n  ##\n  resources:\n    ## Example:\n    ## limits:\n    ##    cpu: 100m\n    ##    memory: 128Mi\n    ##\n    limits: {}\n    ## Examples:\n    ## requests:\n    ##    cpu: 100m\n    ##    memory: 128Mi\n    ##\n    requests: {}\n  ## Init container' Security Context\n  ## Note: the chown of the data folder is done to containerSecurityContext.runAsUser\n  ## and not the below volumePermissions.containerSecurityContext.runAsUser\n  ## @param volumePermissions.containerSecurityContext.runAsUser User ID for the init container\n  ##\n  containerSecurityContext:\n    runAsUser: 0\n\n"
            ],
            "verify": false,
            "version": "11.12.0",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_pod",
      "name": "nginx",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "id": "default/terraform-example",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {
                  "app": "nginx"
                },
                "name": "terraform-example",
                "namespace": "default",
                "resource_version": "2728",
                "uid": "a9f81878-9f51-40fd-8bc8-323a02af8720"
              }
            ],
            "spec": [
              {
                "active_deadline_seconds": 0,
                "affinity": [],
                "automount_service_account_token": true,
                "container": [
                  {
                    "args": [],
                    "command": [],
                    "env": [],
                    "env_from": [],
                    "image": "nginx:1.23.2",
                    "image_pull_policy": "IfNotPresent",
                    "lifecycle": [],
                    "liveness_probe": [],
                    "name": "example",
                    "port": [],
                    "readiness_probe": [],
                    "resources": [
                      {
                        "limits": {},
                        "requests": {}
                      }
                    ],
                    "security_context": [],
                    "startup_probe": [],
                    "stdin": false,
                    "stdin_once": false,
                    "termination_message_path": "/dev/termination-log",
                    "termination_message_policy": "File",
                    "tty": false,
                    "volume_mount": [],
                    "working_dir": ""
                  }
                ],
                "dns_config": [],
                "dns_policy": "ClusterFirst",
                "enable_service_links": true,
                "host_aliases": [],
                "host_ipc": false,
                "host_network": false,
                "host_pid": false,
                "hostname": "",
                "image_pull_secrets": [],
                "init_container": [],
                "node_name": "docker-desktop",
                "node_selector": {},
                "priority_class_name": "",
                "readiness_gate": [],
                "restart_policy": "Always",
                "runtime_class_name": "",
                "scheduler_name": "default-scheduler",
                "security_context": [],
                "service_account_name": "default",
                "share_process_namespace": false,
                "subdomain": "",
                "termination_grace_period_seconds": 30,
                "toleration": [],
                "topology_spread_constraint": [],
                "volume": []
              }
            ],
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjozMDAwMDAwMDAwMDAsImRlbGV0ZSI6MzAwMDAwMDAwMDAwfSwic2NoZW1hX3ZlcnNpb24iOiIxIn0="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_service",
      "name": "nginx",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "id": "default/terraform-example",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {},
                "name": "terraform-example",
                "namespace": "default",
                "resource_version": "2734",
                "uid": "aedeb874-f8b9-4be0-be45-f34b16ed2916"
              }
            ],
            "spec": [
              {
                "allocate_load_balancer_node_ports": true,
                "cluster_ip": "10.104.93.141",
                "cluster_ips": [
                  "10.104.93.141"
                ],
                "external_ips": [],
                "external_name": "",
                "external_traffic_policy": "Cluster",
                "health_check_node_port": 0,
                "internal_traffic_policy": "Cluster",
                "ip_families": [
                  "IPv4"
                ],
                "ip_family_policy": "SingleStack",
                "load_balancer_class": "",
                "load_balancer_ip": "",
                "load_balancer_source_ranges": [],
                "port": [
                  {
                    "app_protocol": "",
                    "name": "",
                    "node_port": 30618,
                    "port": 80,
                    "protocol": "TCP",
                    "target_port": "80"
                  }
                ],
                "publish_not_ready_addresses": false,
                "selector": {
                  "app": "nginx"
                },
                "session_affinity": "None",
                "session_affinity_config": [],
                "type": "NodePort"
              }
            ],
            "status": [
              {
                "load_balancer": [
                  {
                    "ingress": [
                      {
                        "hostname": "localhost",
                        "ip": ""
                      }
                    ]
                  }
                ]
              }
            ],
            "timeouts": null,
            "wait_for_load_balancer": true
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDB9LCJzY2hlbWFfdmVyc2lvbiI6IjEifQ==",
          "dependencies": [
            "kubernetes_pod.nginx"
          ]
        }
      ]
    }
  ]
}
